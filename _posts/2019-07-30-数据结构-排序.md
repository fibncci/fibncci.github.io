---
layout: post
title: "《数据结构与算法》的学习-python3排序"
date: 2019-08-28
tag: dataStructure
---





## Algorithms and Data Structures

算法和数据结构

```
1.数据结构可视化-旧金山大学的网站
神软件
https://www.cs.usfca.edu/~galles/visualization/Algorithms.html
2.Python语言参考
https://docs.python.org/3/reference/index.html
```



1.各种排序的复杂度对比：![](/images/posts/process/排序复杂度比较.jpg)

![](../images/posts/process/排序复杂度比较.jpg)

2.算法执行的时间：![](/images/posts/process/排序.png)

![](../images/posts/process/排序.png)

3.排序的内存使用：![](/images/posts/process/内存使用.jpg)



![](../images/posts/process/内存使用.jpg)



## 为什么要学习算法

计算机科学家经常通过经验学习。我们通过看别人解决问题和自己解决问题来学习。接触不同的问题解决技术，看不同的算法设计有助于我们承担下一个具有挑战性的问题。通过思考许多不同的算法，我们可以开始开发模式识别，以便下一次出现类似的问题时，我们能够更好地解决它。

算法通常彼此完全不同。考虑前面看到的 `sqrt` 的例子。完全可能的是，存在许多不同的方式来实现细节以计算平方根函数。一种算法可以使用比另一种更少的资源。一个算法可能需要 10 倍的时间来返回结果。我们想要一些方法来比较这两个解决方案。即使他们都工作，一个可能比另一个“更好”。我们建议使用一个更高效，或者一个只是工作更快或使用更少的内存的算法。当我们研究算法时，我们可以学习分析技术，允许我们仅仅根据自己的特征而不是用于实现它们的程序或计算机的特征来比较和对比解决方案。

在最坏的情况下，我们可能有一个难以处理的问题，这意味着没有算法可以在实际的时间量内解决问题。重要的是能够区分具有解决方案的那些问题，不具有解决方案的那些问题，以及存在解决方案但需要太多时间或其他资源来合理工作的那些问题。

经常需要权衡，我们需要做决定。作为计算机科学家，除了我们解决问题的能力，我们还需要了解解决方案评估技术。最后，通常有很多方法来解决问题。找到一个解决方案，我们将一遍又一遍比较，然后决定它是否是一个好的方案。







## 1.冒泡排序

找最大值，第二大的值。

简单来说就是比较前后，找到一个大的数再与其他后面的数比较，最后确定最大值；

举例子

``` 
1 5 7 6 3 2 9  (原始数据)
1 5 6 3 2 7 9 （选找到最大数据 5 6 7 9依次交换；找到9 ）
1 5 3 2 6 7 9 （找到7）
1 3 2 5 6 7 9	（找到6）
1 2 3 5 6 7 9 （找到5，无交换）
1 2 3 5 6 7 9 （1 2 比较）
```

```python
#  冒泡排序：它重复的走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来，走访数列的工作是重复的执行到没有再需要交换，也就是说该数列已经完成排序。
#时间复杂度 O(n^2)
#空间复杂度：O(1)
#稳定性：稳定

def bubble_sort(blist):
    count = len(blist)
    for i in range(0,count):
        for j in range(i+1,count):
            if blist[i] > blist[j]:
                blist[i],blist[j] = blist[j],blist[i]
    return blist

print(bubble_sort([4,5,6,7,8,2,3,1,0]))
```









## 2.插入排序

最前面两个先比较，然后第三个与前面做比较。

类似于冒泡排序；优化算法，如果加入一些判断，当做比较的时候，小于第一个数，或者大于最后一个数直接停止。

```
举例子
4 5 2 3 9 1
4 5 2 3 9 1 (5与4 比较，4的位置确定)
4 5 2 3 9 1 （2 与 4 5 分别比较，确定245）
2 4 5 3 9 1 （3与2 4 5 分别比较，确定2453）
2 3 4 5 9 1 （9与 5 比较 ，确定23459 ）
2 3 4 5 9 1	（1分别与1 2 3 4 5 9做比较）
1 2 3 4 5 9 （输出）  
```

```python
#1 插入排序:插入排序的基本操作就是将一个数据插入到已经排好序的有序数据中，从而得到一个新的，个数加1 的有序数据，算法用于少量数据的排序，首先将第一个作为已经排好序的，然后每次从后的取出插入到前面并排序。
''' 
时间复杂度 O(n^2)
空间复杂度：O(1)
稳定性：稳定
'''
def insert_sort(ilist):
    for i in range(len(ilist)):
        for j in range(i):
            if ilist[i] < ilist[j]:
                ilist.insert(j,ilist.pop(i))
                break
    return ilist

print(insert_sort([4,6,7,3,2,1,8,0]))

```







## 3.快速排序

确定元素的位置，从后往前；时间复杂度：最好和平均情况是O(nlogn)；最坏事O（n^2）(123456顺序数列)

举例子

```
满足：1.比6小于等于就交换；2 大于就与i+1 与 j+1 交换。
4 1 3 5 8 2 9 6
i j
1 4 3 5 8 2 9 6
1 3 4 5 8 2 9 6
1 3 5 4 8 2 9 6
1 3 5 4 2 8 9 6
1 3 5 4 2 6 8 9 第一次确定了6的位置。分为两类了 13542 89
1 3 5 4 2 
1 3 5 4 2 ...
1 2 3 5 4 第二次确定2 的位子 1 354 
3 5 4
3 4 5 
1 2 3 4 5 6 8 9结束
```

举例子2

```
7 3 5 1 6 2 8 4 
3 7 5 1 6 2 8 4 第一步，找位置 i为7前面，j为7上；第二步 ，7>4 ，则3为j，7 为 i；第三步，3<4 ，则交换
i   j
3 1 5 7 6 2 8 4 i+1与j+1交换
3 1 2 7 6 5 8 4
312 4 6587 最后确定4 的位置；分为2类 第一次
1 3 2 
1 2 3 末尾，就调整换 ；i+1 与j
6 5 8 7 
65 7 8  第二次分类
123 4 5678 结束
```

```python
"""

 快速排序：是目前基于比较的内部排序中被认为是最好的方法，当待排序的关键字是随机分布时，快速排序的平均时间最短；

通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列
时间复杂度：O(nlog₂n)
空间复杂度：O(nlog₂n)
稳定性：不稳定

"""
#快排的主函数，传入参数为一个列表，左右两端的下标
def QuickSort(array,leftIndex=0,rightIndex=None):
    #数组的长度
    arrayLen = len(array)
    #长度为1 的话 或者 空 的话 直接返回 数组
    if arrayLen <= 1:
        return array
    #程序一开始 如果没有给一个最右边的索引值导入话，那么我们就给它 赋值一个 就是数组的最右边的 那个索引值。
    if rightIndex == None:
        rightIndex = arrayLen - 1
    # 保护条件，只有满足  左边索引小于右边索引的时候 再开始排序
    if leftIndex < rightIndex:
        #找到 基准的 索引值 传入参数，通过Partitions函数，获取k下标值
        pivot = partition(array,leftIndex,rightIndex)
        #递归前后半区 对基准前面不部分继续快排
        QuickSort(array,leftIndex,pivot - 1)
        #对基准后半积分继续快排
        QuickSort(array,pivot + 1,rightIndex)

def partition(array,leftIndex,rightIndex):

    pivotValue = array[rightIndex]
    #将最左侧的 索引值 给 i
    i  = leftIndex
    #将最右侧的 索引的前一个 给j
    j = rightIndex -1
    #当left下标，小于right下标的情况下，此时判断二者移动是否相交，若未相交，则一直循环
    while i < j:
        # 当left对应的值大于锚点 基准点 参考值，就一直向左移动
        while j > leftIndex and array[j] > pivotValue:
            j -= 1
        #当left对应的值小于基准点参考值，就一直向右移动
        while i < rightIndex and array[i] <= pivotValue:
            i += 1
        #若移动完，二者仍未相遇则交换下标对应的值
        if i < j:
            array[j],array[i] = array[i],array[j]
            i+=1
            j-=1
    #若移动完，已经相遇，则交换right对应的值和参考值
    array[i],array[rightIndex] = array[rightIndex],array[i]
    # 返回 一个 索引值
    return i

# 《算法导论》中的快排程序
def partition2(array,leftIndex,rightIndex):
    #设置一个 左边的指针位置 为 左侧的 前一个
    i = leftIndex -1
    #遍历 除 基准数之外的 数
    for j in range(leftIndex,rightIndex):
        #比较 遍历的数 和 基准数 ，若是小于基准数 则 换到数组前面去
        if array[j] < array[rightIndex]:
            #交换位置，将遍历的比 基准数小的数 放到 我们指针 的 后一个上，然后 这个时候指针向后移一位。当遍历的数大于我们的基准数的时候，不移动，而且 指针也不发生变化，那么 当我们遍历完一圈以后，把 我们的基准数 放到 索引i 的后一个 位置，那么就形成了 一个 基准数 左边都是比它小的数，基准数右边 都是比它大的数 这样的模式。然后要把 索引 i 的后一个位置 作为基准数 与 原基准数 交换位置，进而可以第二次来 遍历比较。
            array[j],array[i+1] = array[i+1],array[j]
            i += 1
    #遍历完了以后，将 left 位置上的数 和 最后一个 数  即 right 上的数互换位置，就 重置 基准数了。
    array[rightIndex],array[i+1] = array[i+1],array[rightIndex]
    #返回基准的下标
    return i+1



if __name__ == '__main__':
    array = [14,33,27,10,35,19,42,44]
    QuickSort(array)
    print(array)
```





## 4.并排排序

大数据里面 Hadoop计算Map-reduce的思想；1变多是map；多变1是reduce

举例子

```
3425176
3 42 51 76
3 4 2 5 1 7 6		每一个都是泡脚序的（扩散）；以空间换时间？
3 24 15 67
234 1567 结束
时间复杂度：（n-1）*（logn+1） = nlogn +n-logn+1 取最大项
```

```python
#      当n较大，则应采用时间复杂度为O(nlog2n)的排序方法：快速排序、堆排序或归并排序序。

"""
归并排序：采用分治法（Divide and Conquer）的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为二路归并

时间复杂度：O(nlog₂n)
空间复杂度：O(1)
稳定性：稳定

"""

# 归并排序 Merge_Sort

def MergeSort(arrayList):
    arrayLen = len(arrayList)
    #判断输入参数的正确性,如果长度小于1，就说明为1
    if arrayLen <= 1:
        return arrayList
    midIndex = arrayLen//2
    #左边的部分去做 MergeSort
    leftArray = MergeSort(arrayList[:midIndex])
    #右边的去做 MergeSort
    rightArray = MergeSort(arrayList[midIndex:])
    #将左右两边合并，称为一个新的数组，并已经排序成功
    retArray = MergeCore(leftArray,rightArray)
    return retArray

def MergeCore(leftArray,rightArray):
    #首先需要定义两个指针,这两个指针，分别指向这两个数组的第一个元素
    leftIndex = 0
    rightIndex = 0
    #获取两个数组的长度，用于指出上面两个指针的边界是什么
    leftLen = len(leftArray)
    rightLen = len(rightArray)
    #定义一个返回的列表,这一步就代表空间复杂度至少是 O(n)
    retList = []
    #循环两个数组寻找最小值加入到返回值的数组中
    while leftIndex < leftLen and rightIndex < rightLen:
        if leftArray[leftIndex] < rightArray[rightIndex]:
            retList.append(leftArray[leftIndex])
            leftIndex += 1
        else:
            retList.append(rightArray[rightIndex])
            rightIndex += 1
    #下面的代码是将剩余的数组中内容放置在返回的数组中
    retList.extend(leftArray[leftIndex:])

    # while leftIndex < leftLen:
    #     retList.append(leftArray[leftIndex])
    #     leftIndex += 1

    retList.extend(rightArray[rightIndex:])

    # while rightIndex < rightLen:
    #     retList.append(rightArray[rightIndex])
    #     rightIndex += 1
    return retList


if __name__ == '__main__':
    # 14,33,27,10,35,19,42,44

    retList = MergeSort([14,33,27,10,35,19,42,44])
    print(retList)
```



## 5.选择排序

```python
# 选择排序 ： 第一趟，在待排序记录r1 。。。r(n)中选出最小的记录，将它与r1 交换，第二趟，在待排序记录r2 ~ r(n) 中选出最小的记录，将它与 r2 交换，以此类推，第i趟在待排序记录 r[i]~r[n]中选出最小的记录，将它与r[i]交换，使有序序列不断增长直到全部排序完毕。

#时间复杂度 O(n^2)
#空间复杂度：O(1)
#稳定性：不稳定

def select_sort(slist):
    #外层循环控制循环次数
    for i in range(len(slist)):
        #假设找到的最小元素下标为j
        x = i
        #寻找最小元素的过程
        for j in range(i,len(slist)):
            #假设最小下标的值，大于循环中一个元素，那么就改变最小值的下标
            if slist[j] < slist[x]:
                x = j
        #循环一开始就假设把最小值的下标赋值给变量 x
        # 在不停的循环中，不停的交换两个不一样大小的值
        slist[i],slist[x] = slist[x],slist[i]
    #返回 排好序的列表
    return slist



if __name__ == '__main__':
    arrayList = [4,5,6,7,3,2,6,9,8]
    select_sort(arrayList)
    print(arrayList)
```

------

## 6.希尔排序

python中的集合set就是哈希排序

```python
#4 希尔排序 ： 希尔排序 是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰好被分成一组，算法终止

#时间复杂度 O(n^2)
#空间复杂度：O(nlogn)
#稳定性：不稳定

def shell_sort(slist):
    count = len(slist)
    step = 2
    group = count // step
    while group>0:
        for i in range(group):
            j = i + group
            while j < count:
                key = slist[j]
                k = j - group
                while k >= 0:
                    if slist[k] > key:
                        slist[k+group] = slist[k]
                        slist[k] = key
                    k = k - group
                j = j + group
        group = group // step
    return slist

# print(shell_sort([4,5,7,3,2,6,9,8,0]))

def ShellSort(arrList):
    arrayLen = len(arrList)
    h = 1
    while h < arrayLen//3:
        h = h * 3 + 1
        #插入排序的方法，判断是不是后一个比前一个要小
        #如果是则交换
    while h >= 1:
        for i in range(h,arrayLen):
            j = i
            while j >= h and arrList[j] < arrList[j-h]:
                arrList[j] ,arrList[j-h] = arrList[j-h],arrList[j]
                j -= h
        h  //= 3


if __name__ == '__main__':
    arrList = [14,33,27,10,35,19,42,44]
    ShellSort(arrList)
    print(arrList)
```

## 拓展：海量数据处理

----外部归并排序 - 分治.cppp

数据结构与算法处理的都是大数据，大量的数据。现在有100亿的数字排序，100亿个 int 型数字放在文件里面大概有 37.2GB，非常大，内存一次装不下了。那么肯定是要拆分成小的文件一个一个来处理，最终在合并成一个排好序的大文件。

#### 实现思路

1.把这个37GB的大文件，用哈希分成1000个小文件，每个小文件平均38MB左右（理想情况），把100亿个数字对1000取模，模出来的结果在0到999之间，每个结果对应一个文件，所以我这里取的哈希函数是 h = x % 1000，哈希函数取得”好”，能使冲突减小，结果分布均匀。

2.拆分完了之后，得到一些几十MB的小文件，那么就可以放进内存里排序了，可以用快速排序，归并排序，堆排序等等。

3.1000个小文件内部排好序之后，就要把这些内部有序的小文件，合并成一个大的文件，可以用二叉堆来做1000路合并的操作，每个小文件是一路，合并后的大文件仍然有序。
首先遍历1000个文件，每个文件里面取第一个数字，组成 (数字, 文件号) 这样的组合加入到堆里（假设是从小到大排序，用小顶堆），遍历完后堆里有1000个 (数字，文件号) 这样的元素 然后不断从堆顶拿元素出来，每拿出一个元素，把它的文件号读取出来，然后去对应的文件里，加一个元素进入堆，直到那个文件被读取完。拿出来的元素当然追加到最终结果的文件里。 按照上面的操作，直到堆被取空了，此时最终结果文件里的全部数字就是有序的了。 最后我用c++写了个实验程序，具体代码在这里可以看到。

#### 如何拆分大文件？

一个32G的大文件，用fopen()打开不会全部加载到内存的，然后for循环遍历啊，把每个数字对1000取模，会得到0到999种结果，然后每种结果在写入到新的文件中，就拆分了

对 2 亿个数字进行排序, 约 10 G 的文件, 每个数字 int 能表示；



#### c语言

```c
// 算法流程
 // 将 10 G 的文件散列到 300 个文件中, 每个文件大约 35 MB
 // 对 35 MB 的小文件内部排序, 或者分发到多台计算机中, 并行处理 MapReduce
 // 最后使用最小堆, 进行 300 路归并排序, 合成大文件
 // 再写一个算法判断 2 亿个数字是否有序
  
 #include <stdio.h>
 	#include <stdlib.h>
 	#include <time.h>
 	#include <io.h>
 	#include <queue>
 
 	#define FILE_NUM 300 // 哈希文件数
 	#define HASH(a) (a % FILE_NUM)

 	int num = 6000000; // 2 亿个数字, 手动改
 	char path[20] = "c:\\data.dat"; // 待排文件
 	char result[20] = "c:\\result.dat"; // 排序后文件
 	char tmpdir[100] = "c:\\hashfile"; // 临时目录
 	22	 
 	// 随机生成 2 亿个数字
 	int write_file(void)
 	{
 	　　FILE *out = NULL;
 	　　int i;
 	 
 	　　printf("\n正在生成 %d 个数字...\n\n", num);
 		　　out = fopen(path, "wt");
 　if (out == NULL) return 0;
 		 
 		　　unsigned int s, e;
 		　　e = s = clock();
 		　　for (i=0; i<num; i++)
 		　　{
 		　　　　e = clock();
 		　　　　if (e - s > 1000) // 计算进度
 		　　　　{
 		　　　　　　printf("\r处理进度 %0.2f %%\t", (i * 100.0) / num);
 		　　　　　　s = e;
 		　　　　}
 		　　　　fprintf(out, "%d\n",
 		　　　　　　　　(rand() % 31623) * (rand() % 31623));
 		　　}
 		　　fclose(out);
 		　　return 1;
 		}
 		 
 		// 对 2 亿个数字进行哈希, 分散到子文件中
 		// 入口参数: path, tmpdir
 		int map(void)
 		{
 		　　FILE *in = NULL;
 		　　FILE *tmp[FILE_NUM + 5];
 		　　char hashfile[512]; // 哈希文件地址
 		　　int data, add;
 		　　int i;
 		 
 		　　printf("\r正在哈希 %s\n\n", path);
 		　　in = fopen(path, "rt");
 		　　if (in == NULL) return 0;
 		　　for (i=0; i<FILE_NUM; i++) tmp[i] = NULL;
 		 
 		　　// 开始哈希, 核心代码要尽可能的加速
 		　　unsigned int s, e;
 		　　e = s = clock();
 		　　i = 0;
 		　　while (fscanf(in, "%d", &data) != EOF)
 		　　{
 		　　　　add = HASH(data);
 		　　　　if (tmp[add] == NULL)
 		　　　　{
 		　　　　　　sprintf(hashfile, "%s\\hash_%d.~tmp", tmpdir, add);
 		　　　　　　tmp[add] = fopen(hashfile, "a");
 		　　　　}
 		　　　　fprintf(tmp[add], "%d\n", data);
 		 
 		　　　　i++;
 		　　　　e = clock(); // 计算进度
 		　　　　if (e - s > 1000)
 		　　　　{
 		　　　　　　printf("\r处理进度 %0.2f %%\t", (i * 100.0) / num);
 		　　　　　　s = e;
 		　　　　}
 		}　
 		　　for (i=0; i<FILE_NUM; i++)
 		　　if (tmp[i]) fclose(tmp[i]);
 		　　fclose(in);
 		 
 		　　return 1;
 		}
 		 
 		// 对 300 个文件逐个排序, 采用堆排序 STL 的优先队列
 		void calc(void)
 		{
 		　　int fileexist(char *path); // 判断文件存在
 		　　std::priority_queue<int> q; // 堆排序
 		　　char hashfile[512];
 		　　FILE *fp = NULL;
 		　　int i, data;
 		 
 		　　// 逐个处理 300 个文件, 或者将这些文件发送到其它计算机中并行处理
 		　　for (i=0; i<FILE_NUM; i++)
 		　　{
 		　　　　sprintf(hashfile, "%s\\hash_%d.~tmp", tmpdir, i);
 		　　　　if (fileexist(hashfile))
 		　　　　{
 		　　　　　　printf("\r正在排序 hash_%d.~tmp\t", i);
 		 
 		　　　　　　// 小文件从磁盘加入内存中
 		　　　　　　fp = fopen(hashfile, "rt");
 		　　　　　　while (fscanf(fp, "%d", &data) != EOF)
 		　　　　　　{
 		　　　　　　　　q.push(data);
 		　　　　　　　　// 优先队列默认是大顶堆, 即降序排序
 		　　　　　　　　// 要升序需要重载 () 运算符
 		　　　　　　}
 		　　　　　　fclose(fp);
 		 
 		　　　　　　// 排序后再从内存写回磁盘
 		　　　　　　fp = fopen(hashfile, "wt"); // 覆盖模式写
 		　　　　　　while (!q.empty())
 		　　　　　　{
 		　　　　　　　　fprintf(fp, "%d\n", q.top());
 		　　　　　　　　q.pop();
 		　　　　　　}
 		　　　　　　fclose(fp);
 		　　　　}
 		　　}
 		}
 		 
 		typedef struct node // 队列结点
 	{
 		　　int data;
 		　　int id; // 哈希文件的编号
 		　　bool operator < (const node &a) const
 		　　{ return data < a.data; }
 		}node;
 		 
 		// 将 300 个有序文件合并成一个文件, K 路归并排序
 		int reduce(void)
 		{
 		　　int fileexist(char *path);
 		　　std::priority_queue<node> q; // 堆排序
 		　　FILE *file[FILE_NUM + 5];
 		　　FILE *out = NULL;
 		　　char hashfile[512];
 		　　node tmp, p;
 		　　int i, count = 0;
 		 
 		　　printf("\r正在合并 %s\n\n", result);
 		　　out = fopen(result, "wt");
 		　　if (out == NULL) return 0;
 		　　for (i=0; i<FILE_NUM; i++) file[i] = NULL;
 		　　for (i=0; i<FILE_NUM; i++) // 打开全部哈希文件
 		　　{
 		　　　　sprintf(hashfile, "%s\\hash_%d.~tmp", tmpdir, i);
 		　　　　if (fileexist(hashfile))
 		　　　　{
 	　　　　　　file[i] = fopen(hashfile, "rt");
 		　　　　　　fscanf(file[i], "%d", &tmp.data);
 		　　　　　　tmp.id = i;
 		　　　　　　q.push(tmp); // 初始化队列
 		　　　　　　count++; // 计数器
 		　　　　　　printf("\r入队进度 %0.2f %%\t", (count * 100.0) / FILE_NUM);
 		　　　　}
 		　　}
 		　　unsigned int s, e;
 		　　e = s = clock();
 		　　while (!q.empty()) // 开始 K 路归并
 		　　{
 	　　　　tmp = q.top();
 		　　　　q.pop();
 		　　　　// 将堆顶的元素写回磁盘, 再从磁盘中拿一个到内存
 		　　　　fprintf(out, "%d\n", tmp.data);
 		　　　　if (fscanf(file[tmp.id], "%d", &p.data) != EOF)
 		　　　　{
 		　　　　　　p.id = tmp.id;
 		　　　　　　q.push(p);
 		　　　　　　count++;
 		　　　　}
 		 
 		　　　　e = clock(); // 计算进度
 		　　　　if (e - s > 1000)
 		　　　　{
 		　　　　　　printf("\r处理进度 %0.2f %%\t", (count * 100.0) / num);
 		　　　　　　s = e;
 		　　　　}
 		　　}
 	　　for (i=0; i<FILE_NUM; i++)
 	　　if (file[i]) fclose(file[i]);
 	　　fclose(out);
 	 
 	　　return 1;
 	}
 	 
 	int check(void) // 检查是否降序排序
 	{
 	　　FILE *in = NULL;
 	　　int max = 0x7FFFFFFF;
 	　　int data;
 	　　int count = 0;
 	 
 	　　printf("\r正在检查文件正确性...\n\n");
 	　　in = fopen(result, "rt");
 	　　if (in == NULL) return 0;
 	 
 	　　unsigned int s, e;
 	　　e = s = clock();
 	　　while (fscanf(in, "%d", &data) != EOF)
 	　　{
 	　　　　if (data <= max) max = data;
 	　　　　else
 	　　　　{
 	　　　　　　fclose(in);
 	　　　　　　return 0;
 	　　　　}
 	　　　　count++;
 	　　　　e = clock(); // 计算进度
 	　　　　if (e - s > 1000)
 	　　　　{
 	　　　　　　printf("\r处理进度 %0.2f %%\t", (count * 100.0) / n
 	　　　　　　s = e;
 	　　　　}
 	　　}
 	　　fclose(in);
 	　　return 1;
 	}
 	 
 	// 判断文件存在
 	int fileexist(char *path)
 	{
 	　　FILE *fp = NULL;
 	 
 	　　fp = fopen(path, "rt");
 	　　if (fp)
 	　　{
 	　　　　fclose(fp);
 	　　　　return 1;
 	　　}
 	　　else return 0;
 	}
 	 
 	int main(void)
 	{
 	　　char cmd_del[200]; // 删除目录
 	　　char cmd_att[200]; // 设置隐藏
 	　　char cmd_mkdir[200]; // 建立目录
 	 
 	　　// 初始化 cmd 命令, 建立工作目录
 	　　sprintf(cmd_del, "rmdir /s /q %s", tmpdir);
 	　　sprintf(cmd_att, "attrib +h %s", tmpdir);
 	　　sprintf(cmd_mkdir, "mkdir %s", tmpdir);
 	　　if (access(path, 0) == 0) system(cmd_del);
 	　　system(cmd_mkdir); // 建立工作目录
 	　　system(cmd_att); // 隐藏目录
 	 
 	　　// 随机生成 2 亿个数字
 	　　if (!write_file()) return 0;
 	 
 	　　map(); // 对 2 亿个数字进行哈希, 即 Map
 	　　calc(); // 对 300 个文件逐个排序
 	　　reduce(); // 最后将 300 个有序文件合并成一个文件, 即 reduce
 	　　if (check()) printf("\r排序正确!\t\t\t\n\n");
 	　　else printf("\r排序错误!\t\t\t\n\n");
 	 
 	　　system(cmd_del); // 删除哈希文件
 	　　remove(path); // 删除 2 亿数字文件
 	　　remove(result); // 删除排序后的文件
 	 
 		　　return 0;
 	}
```





## 树

#### 二叉查找树

我们已经看到了两种不同的方法来获取集合中的键值对。回想一下，这些集合实现了 `map` 抽象数据类型。我们讨论的 `map` ADT 的两个实现是在列表和哈希表上的二分搜索。在本节中，我们将研究二叉查找树作为从键映射到值的另一种方法。 在这种情况下，我们对树中项的确切位置不感兴趣，但我们有兴趣使用二叉树结构来提供高效的搜索。











### python 3 二叉 树

数据结构是啥：就是树模型；；

```python
class TreeNode(object):
    def __init__(self,value):
        self.x = value
        self.left = None
        self.right = None
        #当很多数据的时候，可以用数组 self.children = []
          
root = TreeNode(5)
node_left = TreeNode(3)
node_right = TreeNode(9)

root.left = node_left
root.right =node_right

node_left3 = TreeNode(1)
node_right3 = TreeNode(4)
node_left.left =node_left3
node_left.right = node_right3

node_left9 = TreeNode(6)
node_right9 = TreeNode(10)

node_right.left = node_left9
node_right.right = node_right9
# 先根遍历
def preroot(root):
    if root:
        print(root.x,end=',')
        preroot(root.left)
        preroot(root.right)
preroot(root)
# 5,3,1,4,9,6,10,

,
# 中根遍历
def midroot(root):
    if root:
        midroot(root.left)
        print(root.x,end= ',')
        midroot(root.right)
midroot(root)
# 1,3,4,5,6,9,10,

# 中根遍历
def beroot(root):
    if root:
        beroot(root.left)
        beroot(root.right)
        print(root.x,end= ',')
        
beroot(root)

#1,4,3,6,10,9,5,
```

树的遍历（是否用递归）

```python
# -*- coding:utf-8 -*-

class TreeNode(object):
    def __init__(self, x):
        self.val = x
        self.left = None
        self.right = None

# 1.深度优先
# 2.广度优先

'''
对于深度优先来说：
    1.先序遍历（根、左、右）
    2.中序遍历（左、根、右）
    3.后序遍历（左、右、根）
    注意：先序、中序后序都是对应于根节点来说的，左右节点都是先左后右
'''

# 递归
# 前序法
def preOrderRecusive(root):
    if root == None:
        return None
    print('[%2d]' %root.val, end=' ')
    preOrderRecusive(root.left)
    preOrderRecusive(root.right)

# 中序法
def midOrderRecusive(root):
    if root == None:
        return None
    midOrderRecusive(root.left)
    print('[%2d]' %root.val, end=' ')
    midOrderRecusive(root.right)

# 后序法
def latOrderRecusive(root):
    if root == None:
        return None
    latOrderRecusive(root.left)
    latOrderRecusive(root.right)
    print('[%2d]' %root.val, end=' ')


# 非递归的形式，先根，中根，后跟
# 前序法
def preOrder(root):
    if root == None:
        return None

    stack = []
    tmpNode = root
    while tmpNode or stack:
        while tmpNode:
            print(tmpNode.val)
            stack.append(tmpNode)
            tmpNode = tmpNode.left
        node = stack.pop()
        tmpNode = node.right

# 中序法
def midOrder(root):
    if root == None:
        return None

    stack = []
    tmpNode = root
    while tmpNode or stack:
        while tmpNode:
            stack.append(tmpNode)
            tmpNode = tmpNode.left
        node = stack.pop()
        print(node.val)
        tmpNode = node.right

# 后序法
def latOrder(root):
    if root == None:
        return None

    stack = []
    tmpNode = root
    while tmpNode or stack:
        while tmpNode:
            stack.append(tmpNode)
            tmpNode = tmpNode.left
        node = stack[-1]
        tmpNode = node.right
        if node.right == None:
            print(node.val)
            node = stack.pop()
            while stack and node == stack[-1].right:
                node = stack.pop()
                print(node.val)


if __name__ == '__main__':
    t1 = TreeNode(1)
    t2 = TreeNode(2)
    t3 = TreeNode(3)
    t4 = TreeNode(4)
    t5 = TreeNode(5)
    t6 = TreeNode(6)
    t7 = TreeNode(7)
    t8 = TreeNode(8)

    t1.left = t2
    t1.right = t3
    t2.left = t4
    t2.right = t5
    t3.left = t6
    t3.right = t7
    t6.right = t8
    # preOrderRecusive(t1)
    # midOrderRecusive(t1)
    # latOrderRecusive(t1)
    # preOrder(t1)
    # midOrder(t1)
    latOrder(t1)
```











## 2-3 树(经典版)



对于二叉搜索树，在剑指offer中多有涉及。我们也都看过其定义，比较好的情况下能够达到 log(n) 的搜索时间复杂度。然而，二叉搜索树一样可能出现极端的情况，例如一颗二叉搜索树只包含右子树。其右子树节点也只包含右子树。循环下去一直到叶节点。如下所示：



![img](https://mmbiz.qpic.cn/mmbiz_png/V993eJeTp4ibHws2267HicRj4PgkOnE5BYFRPJYx9Gl3rAfQvwucuVQVUwh9JGgRzCU0nGM0wEc8exVERhcxElzg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

当这样的情况出现的时候，二叉搜索树的搜索时间复杂度就由 O(log(n)) 退化到了 O(n)，这在计算机的大规模查找中效率下降的很严重，是不可以接受的。前辈们为了防止这样的情况发生，就创造出了2-3树，进而创造出了红黑树。今天我们就来了解2-3树的样子，也就能为后面的红黑树做好铺垫，更好的理解红黑树。一旦能够让树保持平衡的状态，那么时间复杂度也就能稳定的保持在O(log(n)), 这样稳定的性能才是计算机追求的。



**2-3树的定义(维基百科的定义)**

如果一个内部节点拥有一个数据元素、两个子节点，则此节点为2节点。

如果一个内部节点拥有两个数据元素、三个子节点，则此节点为3节点。

当且仅当以下叙述中有一条成立时，*T*为2–3树：

- *T*为空。即*T*不包含任何节点。

- *T*为拥有数据元素*a*的2节点。若*T*的左孩子为*L*、右孩子为*R*，则

- - *L*和*R*是等高的非空2–3树；
  - *a*大于*L*中的所有数据元素；同时
  - *a*小于等于*R*中的所有数据元素。

- *T*为拥有数据元素*a*和*b*的3节点，其中*a* < *b*。若*T*的左孩子为*L*、中孩子为*M*、右孩子为*R*，则

- - *L*、*M*、和*R*是等高的非空2–3树；
  - *a*大于*L*中的所有数据元素，并且小于等于*M*中的所有数据元素；同时
  - *b*大于*M*中的所有数据元素，并且小于等于*R*中的所有数据元素



**2-3树的查找操作**

2-3树的查找操作与二叉搜索树的查找很相似，下面我们就来看下，如何查找一个数据。



\1. 假设T是一个 2-3 树，假设 d 是需要查找的数据。如果 T 是空，那么d不在T中，结束。

\2. 让r是T的跟节点

\3. 假设r是叶节点，如果d没有在r内，那么d也就不在T内。相反，d就在T内。

\4. 假设r是一个2元的节点，包含左子树L和右子树R。让e是r中的一个元素。我们需要思考一下三种情况：

​    a) 如果d等于e，我们就发现了d在T中，并且结束了。

​    b) 如果d小于e，将L设置给T，然后就返回到第二步。

​    c) 如果d大于e，将R设置给T，然后返回到第二步。

\5. 假设r是一个三元节点，包含左子树L，中子树M，右子树R。a 和 b 是 r 中的两个元素，a < b, 就包含以下四种情况：

​    a) 如果d等于a或者b，那么d就在T中，结束

​    b) 如果 d < a, 然后就将L设置给T，然后返回第二步

​    c) 如果 a < d < b, 然后就将M设置给T，返回第二步

​    d) 如果 d > b，然后就将R设置给T，返回到第二步



![img](https://mmbiz.qpic.cn/mmbiz_png/V993eJeTp48YTWPy92iaTYHib4EQfdic6xKoibwVjJ7Skzr2HgQsAkCiaeZUpAsdJ4WYm9iaZDFEncevfem2J6gPkpKw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

**2-3树的插入操作**

先找到需要插入的位置，插入的内容是k，位置就是按照查找的方式找到叶节点 n。这个叶节点有两种情况：

\1. 这个节点是2节点



​    将k放入到节点n中。然后n变成了一个3节点。

![img](https://mmbiz.qpic.cn/mmbiz_png/V993eJeTp48YTWPy92iaTYHib4EQfdic6xKtjEsmbZegFby7FyJYLa3rKrShXXooHiaFNibWyntjve7IxslqGKeZyyA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

\2. 这个节点是3节点

​    a) 假设2-3树只包含一个节点，这个节点又是叶节点。也就是说这个树内只包含一个节点。这个节点是三元的。那么向这个节点插入数据的时候，首先这个节点会临时的变成四个节点，内部有三个元素。这三个元素中中间的新生成一个node叫做m，右边的元素也新生成一个node叫做n，原来的跟节点叫做l。那么n和l和m都是二元的节点。将m变成新的跟节点，l是m的左子树，n是m的右子树。图形如下：

![img](https://mmbiz.qpic.cn/mmbiz_png/V993eJeTp48YTWPy92iaTYHib4EQfdic6xKgRGibvI57Y16dMgWnbtXsaaHQZrdgJgY2FicUMAyRFVMVgZgAxJrMW0g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)



​    b) 如果不是只有一个节点，那么我们通过查找的方式一直查找到叶节点，发现叶节点是三元的，那么就需要像a)中描述的那样，先插入生成临时的4节点，然后将右侧的元素取出，单独生成一个节点。而后将中间节点插入到上层。就循环这个插入过程，直到插入完成。

\#end





## 图片加水印

```
from PIL import Images,ImageDrow,Image
```

