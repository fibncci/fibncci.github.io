---
layout: post
title: "mysql笔记"
date: 2019-12-10
tag: sas
---







mysql -u root -p123456 -h 127.0.0.1 -P3306

# 初始化

- [课程简介](../)
- 1.MySQL数据库
  - [1.1MySQL数据库的安装和配置](1install.html)
  - [1.2MySQL数据库的基本操作](2mysqlji-chu-cao-zuo.html)
  - [1.3Mysql数据类型](3mysqlshu-ju-lei-xing.html)
  - [1.4MySQL建库建表](4mysqljian-ku-jian-biao.html)
  - [1.5MySQL DML操作：增删改](5dmlcao-zuo-ff1a-589e2c-52202c-gai.html)
  - [1.6MySQL DQL操作：数据的查询](6dqlcao-zuo-ff1a-shu-ju-cha-xun.html)
  - [1.7MySQL数据的导入和导出](7shu-ju-dao-ru-he-dao-chu.html)
  - [1.8python连接数据库](8pymysql.html)
  - [1.9python连接数据库曾删改查](9lian-jie.html)
- 2.前端和网络相关内容
  - [2.1HTML简介和网页的基本结构](../network/1html.html)
  - [2.2HTML常用标签](../network/2html.html)
  - [2.3HTML节点树](../network/3html.html)
  - [2.4css常用选择器](../network/4html.html)
  - [2.5网络简介](../network/5html.html)
  - [2.7UDP协议和tcp协议](../network/6html.html)
  - [2.7HTTP协议](../network/7html.html)
- 3.爬虫
  - [3.1python中虚拟环境的使用](../spider/1virtualenv.html)
  - [3.2urllib的使用](../spider/2urllib.html)
  - [3.3urllib解决登录问题](../spider/3urllib.html)
  - [3.5正则re模块](../spider/4re.html)
  - [3.4urllib添加代理](../spider/5proxy.html)
  - [3.7requests的使用](../spider/6requests.html)
- 4.解析模块
  - [4.1jsonpath的基本使用](../spider/7jsonpath.html)
  - [4.2xpath的基本使用](../spider/8xpath.html)
  - [4.3beautifusoup的基本使用](../spider/9beautifulsoup.html)
- 5.线程进程协程
  - [5.1进程](../process/1.html)
  - [5.2线程](../process/2.html)
  - [5.3协程](../process/3.html)
- 6.selenium的使用
  - [6.1PhantomJS的使用](../spider/11selenium.html)
- 7.scrapy框架简介
  - [7.1scrapy框架安装](../scrapy/2.html)
  - [7.2scrapy项目创建](../scrapy/3.html)
  - [7.3scrapy图片下载](../scrapy/4.html)
  - [7.4scrapy UserAgent切换](../scrapy/5.html)
  - [7.4scrapy 代理](../scrapy/6.html)





## 第二阶段课程内容介绍

爬虫主要目的是为了收集数据，所以也叫数据采集，是模仿浏览器向服务端发送请求获取相关信息

本节主要内容 分以下几个模块

- MySQL数据库的基本操作
- 前端和网络相关内容
- urllib requests
- 正则 xpath beautifulsoup jsonpath
- 进程 线程 协程
- selenium
- scrapy



## 1.1 MySQL数据库的安装和配置

## windows下安装

访问官网下载安装包推荐下载5.7：

安装教程：<https://jingyan.baidu.com/article/359911f5ae554557fe0306a2.html>

## ubuntu 下安装

版权声明：本文为博主原创文章，转载请声明原文出处：<http://blog.csdn.net/xiangwanpeng>

首先执行下面三条命令：

```
sudo apt-get install mysql-server

sudo apt install mysql-client

sudo apt install libmysqlclient-dev
```

安装成功后可以通过下面的命令测试是否安装成功：

> sudo netstat -tap | grep mysql

## 配置允许远程连接

首先编辑文件/etc/mysql/mysql.conf.d/mysqld.cnf：

sudo vi /etc/mysql/mysql.conf.d/mysqld.cnf

注释掉bind-address = 127.0.0.1：

保存退出，然后`进入mysql服务`，执行授权命令：

> grant all on *.* to root@'%' identified by '123456' with grant option;

刷新服务

> flush privileges;

退出mysql重新启动mysql服务

> sudo service mysql restart

打开远程连接软件连接

## Ubuntu16.04完全卸载Mysql 5.7

```
sudo apt purge mysql-*
sudo rm -rf /etc/mysql/ /var/lib/mysql
sudo apt autoremove
```

安装时可能或出现的的问题

```
Ubuntu中更新软件时经常会碰到一个问题：
E: 无法获得锁 /var/cache/apt/archives/lock - open (11 资源临时不可用)
E: 无法对下载目录加锁
造成该问题的原因是系统中只允许有一个apt-get进程，当前的锁已经被占用了。我们可以关掉当前的apt-get进程后，再执行我们自己的操作。
解决方案一：
    先执行命令ps aux | grep apt-get，找出当前的apt-get进行，然后kill掉该进程。
解决方案二：
    直接rm rm /var/cache/apt/archives/lock 和 rm /var/lib/dpkg/lock。
终极方案：
    重启系统
```



## 1.2MySQL基础操作

> 使用方法:
>
>  方式一: 通过图型界面工具,如 Navicat 等( 高级课使用 )
>
>  方式二: 通过在命令行敲命令来操作 ( 基础阶段使用 )

 **SQL ( Structure query language ) 结构化查询语言**

```
 SQL语言分为4个部分：
    DDL（Data Definition Languages） :数据的定义
    DML（Data Manipulation Language）:数据的操作        
    DQL（Data Query Language）       :数据的查询操作
    DCL（Date Control Language）     :数据控制语句
```

**SQL语句中的快捷键**

> \G 格式化输出（文本式，竖立显示）
>
> \s 查看服务器端信息
>
> \c 结束命令输入操作
>
> \q 退出当前sql命令行模式
>
> \h 查看帮助

### 操作数据库的步骤

 **连接, 打开库, 操作, 关闭退出**

### 1.通过命令行连接MySQL

![img](./assets/2017-07-10_191111.png)

### 数据库语法的特点

#### 1) SQL 语句可以换行, 要以分号结尾

![img](./assets/2017-03-23_225610.png)

#### 2) 命令不区分大小写. 关键字和函数建议用大写

![img](./assets/2017-03-23_230912.png)

#### 3) 如果提示符为 '> 那么需要输入一个'回车

![img](./assets/2017-03-23_231848.png)

#### 4) 命令打错了换行后不能修改, 可以用 \c 取消

![img](./assets/2017-03-23_232522.png)

### 2. 数据库操作

查看数据库 **show databases;**

创建数据库 **create database 库名 default charset=utf8;**

删除数据库 **drop database 库名;**

打开数据库 **use 库名;**

### 3. 数据表操作

#### 数据库管理系统中, 可以有很多`库`, 每个数据库中可以包括多张数据`表`

![img](./assets/2017-03-23_222501.png)

#### 

#### ![img](./assets/2017-03-23_222238.png)

 查看表: **show tables;**

查看建表语句： **show create tables 表名**

 创建表: **create table 表名(字段名1 类型,字段名2 类型)engine=innodb default charset=utf8;**

 创建表: 如果表不存在,则创建, 如果存在就不执行这条命令

 **create table if not exists 表名(**

 **字段1 类型,**

 **字段2 类型**

 **);**

 删除表: **drop table 表名;**

 表结构: **desc 表名;** 或者 **show columns from 表名**

### 4. 记录操作 增删改查

 插入 **insert into 表名(字段1,字段2,字段3) values(值1,值2,值3);**

 **insert into 表名(字段1,字段2,字段3) values(a值1,a值2,a值3),(b值1,b值2,b值3);**

 查询 **select \* from 表名;**

 **select 字段1,字段2,字段3 from 表名;**

 **select \* from 表名 where 字段=某个值;**

 修改 **update 表名 set 字段=某个值 where 条件;**

 **update 表名 set 字段1=值1,字段2=值2 where 条件;**

 **update 表名 set 字段=字段+值 where 条件;**

 删除 **delete from 表名 where 字段=某个值;**

### 四. 退出MySQL

 **exit;** 或者 **quit;**







# 1.3MySQL 数据类型

### 数值类型

> **tinyint** 1字节 可以表示 0-255 (无符号) 可以表示 -128 ~ 127 (有符号)
>
> **int** 4字节 也分为"有符号"和"无符号"
>
> **decimal** 以字符串形式存储的浮点数 decimal(5, 2) 表示数值总共5位, 小数占2位

### 日期和时间类型

> datetime 8字节 1000-01-01 00:00:00 -- 9999-12-31 23:59:59

### 字符串类型

> **char** 定长字符串
>
> char(7) 不管实际插入多少字符, 它都会占用7个字符位置(中文一个汉字也是一个位置)
>
> **varchar** 变长字符串
>
>  **varchar(7)** 如果实际插入4个字符, 那么它只占4个字符位置
>
> **text** 这种类型用来存放超大文本
>
> **enum** 枚举类型( 多选一 )
>
> **sex enum('w','m','x')** 代表sex这个字段, 可以取 'w', 'm', 'x' 中的一个值

### **表的字段约束**

> **unsigned** 无符号
>
> **int(4)** 显示宽度
>
> **zerofill** 零填充, 位数不够的时候用前导零填充
>
> **not null** 不能为空 在操作数据库时如果输入该字段的数据为NULL ，就会报错
>
> **default** 设置默认值
>
> **primary key** 主键 不能为空 且唯一
>
> **auto_increment** 定义列为自增的属性，一般用于主键，数值会自动加1。
>
> **unique** 唯一

### MySQL的运算符：

> 算术运算符：+ - * / %
>
> 比较运算符：= > < >= <= <> !=
>
> 数据库特有的比较：in，not in, is null,is not null,like, between and
>
> 逻辑运算符：and or not
>
> like: 支持特殊符号%和_ ; 其中 %表示任意数量的任意字符，_表示任意一位字符。

## 数值类型

> MySQL支持所有标准SQL数值数据类型。
>
> 这些类型包括严格数值数据类型(INTEGER、SMALLINT、DECIMAL和NUMERIC)，以及近似数值数据类型(FLOAT、REAL和DOUBLE PRECISION)。
>
> 关键字INT是INTEGER的同义词，关键字DEC是DECIMAL的同义词。
>
> BIT数据类型保存位字段值，并且支持MyISAM、MEMORY、InnoDB和BDB表。
>
> 作为SQL标准的扩展，MySQL也支持整数类型TINYINT、MEDIUMINT和BIGINT。下面的表显示了需要的每个整数类型的存储和范围。

| 类型         | 大小                                     | 范围（有符号）                                               | 范围（无符号）                                               | 用途            |
| ------------ | ---------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | --------------- |
| TINYINT      | 1 字节                                   | (-128，127)                                                  | (0，255)                                                     | 小整数值        |
| SMALLINT     | 2 字节                                   | (-32 768，32 767)                                            | (0，65 535)                                                  | 大整数值        |
| MEDIUMINT    | 3 字节                                   | (-8 388 608，8 388 607)                                      | (0，16 777 215)                                              | 大整数值        |
| INT或INTEGER | 4 字节                                   | (-2 147 483 648，2 147 483 647)                              | (0，4 294 967 295)                                           | 大整数值        |
| BIGINT       | 8 字节                                   | (-9 233 372 036 854 775 808，9 223 372 036 854 775 807)      | (0，18 446 744 073 709 551 615)                              | 极大整数值      |
| FLOAT        | 4 字节                                   | (-3.402 823 466 E+38，-1.175 494 351 E-38)，0，(1.175 494 351 E-38，3.402 823 466 351 E+38) | 0，(1.175 494 351 E-38，3.402 823 466 E+38)                  | 单精度 浮点数值 |
| DOUBLE       | 8 字节                                   | (-1.797 693 134 862 315 7 E+308，-2.225 073 858 507 201 4 E-308)，0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) | 0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) | 双精度 浮点数值 |
| DECIMAL      | 对DECIMAL(M,D) ，如果M>D，为M+2否则为D+2 | 依赖于M和D的值                                               | 依赖于M和D的值                                               | 小数值          |

------

## 日期和时间类型

> 表示时间值的日期和时间类型为DATETIME、DATE、TIMESTAMP、TIME和YEAR。
>
> 每个时间类型有一个有效值范围和一个"零"值，当指定不合法的MySQL不能表示的值时使用"零"值。
>
> TIMESTAMP类型有专有的自动更新特性，将在后面描述。

| 类型      | 大小(字节) | 范围                                    | 格式                | 用途                     |
| --------- | ---------- | --------------------------------------- | ------------------- | ------------------------ |
| DATA      | 3          | 1000-01-01/9999-12-31                   | YYYY-MM-DD          | 日期值                   |
| TIME      | 3          | '-838:59:59'/'838:59:59'                | HH:MM:SS            | 时间值或持续时间         |
| YEAR      | 1          | 1901/2155                               | YYYY                | 年份值                   |
| DATETIME  | 8          | 1000-01-01 00:00:00/9999-12-31 23:59:59 | YYYY-MM-DD HH:MM:SS | 混合日期和时间值         |
| TIMESTAMP | 4          | 1970-01-01 00:00:00/2037 年某时         | YYYYMMDD HHMMSS     | 混合日期和时间值，时间戳 |

------

## 字符串类型

> 字符串类型指CHAR、VARCHAR、BINARY、VARBINARY、BLOB、TEXT、ENUM和SET。该节描述了这些类型如何工作以及如何在查询中使用这些类型。

| 类型       | 大小                | 用途                            |
| ---------- | ------------------- | ------------------------------- |
| CHAR       | 0-255字节           | 定长字符串                      |
| VARCHAR    | 0-65535 字节        | 变长字符串                      |
| TINYBLOB   | 0-255字节           | 不超过 255 个字符的二进制字符串 |
| TINYTEXT   | 0-255字节           | 短文本字符串                    |
| BLOB       | 0-65 535字节        | 二进制形式的长文本数据          |
| TEXT       | 0-65 535字节        | 长文本数据                      |
| MEDIUMBLOB | 0-16 777 215字节    | 二进制形式的中等长度文本数据    |
| MEDIUMTEXT | 0-16 777 215字节    | 中等长度文本数据                |
| LONGBLOB   | 0-4 294 967 295字节 | 二进制形式的极大文本数据        |
| LONGTEXT   | 0-4 294 967 295字节 | 极大文本数据                    |

> CHAR和VARCHAR类型类似，但它们保存和检索的方式不同。它们的最大长度和是否尾部空格被保留等方面也不同。在存储或检索过程中不进行大小写转换。
>
> BINARY和VARBINARY类类似于CHAR和VARCHAR，不同的是它们包含二进制字符串而不要非二进制字符串。也就是说，它们包含字节字符串而不是字符字符串。这说明它们没有字符集，并且排序和比较基于列值字节的数值值。
>
> BLOB是一个二进制大对象，可以容纳可变数量的数据。有4种BLOB类型：TINYBLOB、BLOB、MEDIUMBLOB和LONGBLOB。它们只是可容纳值的最大长度不同。
>
> 有4种TEXT类型：TINYTEXT、TEXT、MEDIUMTEXT和LONGTEXT。这些对应4种BLOB类型，有相同的最大长度和存储需求。





# 1.4MySQL 数据库

### 创建数据库

使用root登录后，可以使用

```
create database if not exists user default charset utf8
```

创建数据库，该命令的作用：

- 如果数据库不存在则创建，存在则不创建。
- 创建RUNOOB数据库，并设定编码集为utf8

### 删除数据库

> **删库有风险,动手需谨慎**
>
> drop database py;

# MySQL 数据表

创建MySQL数据表需要以下信息：

- 表名

- 表字段名

- 定义每个表字段

- ```
  create table 表名(
      字段名 类型 [字段约束],
      字段名 类型 [字段约束],
      字段名 类型 [字段约束]
      ...
  );
  ```

## 创建表

通过 mysql> 命令窗口可以很简单的创建MySQL数据表。你可以使用 SQL 语句**CREATE TABLE**来创建数据表。

### 实例

以下为创建数据表 runoob_tbl 实例:

```
create table user(
    id int unsigned not null AUTO_INCREMENT PRIMARY KEY,
    username varchar(30) not null,
    password char(32) not null,
    email varchar(100) not null,
    pic varchar(50) default './public/img/pic.jpg'
)engine=innodb default charset=utf8;
```

实例解析：

> 如果你不想字段为 NULL 可以设置字段的属性为 NOT NULL， 在操作数据库时如果输入该字段的数据为NULL ，就会报错。
>
> AUTO_INCREMENT定义列为自增的属性，一般用于主键，数值会自动加1。
>
> PRIMARY KEY关键字用于定义列为主键。 您可以使用多列来定义主键，列间以逗号分隔。
>
> ENGINE 设置存储引擎，CHARSET 设置编码。

**查看表结构** desc stu;

**查看建表语句** show create table stu\G --查看建表的语句

## 修改表结构

> 格式： alter table 表名 action（更改选项）;

**添加字段:**

```
添加字段：alter table 表名 add 字段名信息
例如：

-- 在user表的最后追加一个num字段 设置为int not null

alter table user add num int not null;


-- 在user表的email字段后添加一个age字段，设置int not null default 20；

alter table user add age int not null default 20 after email;


-- 在user表的最前面添加一个aa字段设置为int类型

alter table user add aa int first;
```

**删除字段:**

```
删除字段：alter table 表名 drop 被删除的字段名

例如：-- 删除user表的aa字段

 alter table user drop aa;
```

**修改字段:**

```
修改字段：alter table 表名 change\[modify\] 被修改后的字段信息

其中：change可以修改字段名， modify 不修改

例如：

-- 修改user表中age字段信息（类型），（使用modify关键字的目的不修改字段名）

  alter table user modify age tinyint unsigned not null default 20;

-- 修改user表的num字段改为mm字段并添加了默认值（使用change可以改字段名）

  alter table user change num mm int not null default 10;
```

**添加和删除索引:**

```
添加和删除索引

-- 为user表中的name字段添加唯一性索引，索引名为uni_name;
 alter table user add unique uni_name(name);
	==添加索引(括号里面是 字段加索引)
		1.primary key (PRI)主键索引 
			(不可以为空 且唯一 )
		2.unique (UNI)是唯一索引
			(唯一索引的数据具有唯一性)
		3.index	mul 普通索引
		4.全文索引 不支持中文
-- 为user表中的email字段添加普通索引，索引名为index_eamil

 alter table user add index index_email(email);
	   ==删除索引:
	   不管是唯一索引 还是普通索引 都用index
	   ==删除主键索引:
	   	主键.
		 
-- 将user表中index_email的索引删除

 alter table user(表名) drop index index_email(是里面一列);
```

**修改表名:**

```
ALTER TABLE 旧表名 RENAME AS 新表名
alter table 旧表 rename as  新表
rename:重新命名，改名
alter  改变，更改
```

**更改AUTO_INCREMENT初始值:**

```
ALTER TABLE 表名称 AUTO_INCREMENT=1;
alter table 表名 auto_increment=1;
存在不可以改变.ok不代表成功,  自增值不可以改小...
```

**更改表类型:**

```
ALTER TABLE 表名称 ENGINE="InnoDB";
alter table 表名 engine="innodb";
innodb: 支持事务; 将一组操作当做一个执行单元,这一组就是事务.  这一组 sql 只有一个执行失败,全部撤销;要么都成功,要么都失败.
	一组存   取;失败;可以回退;数据的安全性.
	innodb( 引擎,例如外键,索引,存储引擎)
	将数据存到一个文件  字段信息 索引信息  数据效率问题\
	innodb的效率 低于myisam
myisam:不支持事务.(nnodb myisam 磁盘)
		数据不安全
		将数据存在三个文件
keng :服务器重启:
	innodb  重启之后自增值 会重新计算  	12389
	myisam 重启之后自增值  不 会重新计算123  4
```

**关于表类型**

> MySQL数据库中的表类型一般常用两种：MyISAM和InnoDB
>
> 区别：
>
> MyISAM类型的数据文件有三个frm\(结构\)、MYD（数据）、MYI（索引）==后缀
>
> MyISAM类型中的表数据增 删 改速度快，不支持事务，没有InnoDB安全。
>
> InnoDB类型的数据文件只有一个 .frm
>
> InnoDB类型的表数据增 删 改速度没有MyISAM的快，但支持事务，相对安全。

## 删除表

> MySQL中删除数据表是非常容易操作的， 但是你再进行删除表操作时要非常小心，因为执行删除命令后所有数据都会消失。

```
DROP TABLE table_name ;
drop table table_name;  删除
```



# 1.5MySQL 数据操作 DML

> 数据的DML操作：添加数据，修改数据，删除数据

## 添加数据

> 格式： insert into 表名[(字段列表)] values(值列表...);

```
--指定所有字段=标准添加（给定所有的值)
	=>id 可以给NULL占位
mysql> insert into stu(id,name,age,sex,classid) values(1,'zhangsan',20,'m','lamp138');
Query OK, 1 row affected (0.13 sec)

mysql>
--指定部分字段添加值
mysql> insert into stu(name,classid) value('lisi','lamp138');
Query OK, 1 row affected (0.11 sec)

-- 不指定字段添加值
	==>00  values(所有值)
mysql> insert into stu value(null,'wangwu',21,'w','lamp138');
Query OK, 1 row affected (0.22 sec)

-- (一次)批量添加值
	==>加个逗号
mysql> insert into stu values
    -> (null,'zhaoliu',25,'w','lamp94'),
    -> (null,'uu01',26,'m','lamp94'),
    -> (null,'uu02',28,'w','lamp92'),
    -> (null,'qq02',24,'m','lamp92'),
    -> (null,'uu03',32,'m','lamp138'),
    -> (null,'qq03',23,'w','lamp94'),
    -> (null,'aa',19,'m','lamp138');
Query OK, 7 rows affected (0.27 sec)
Records: 7  Duplicates: 0  Warnings: 0
```

## 修改数据

> 格式：update 表名 set 字段1=值1,字段2=值2,字段n=值n... where 条件

```
-- 将id为11的age改为35，sex改为m值
mysql> update stu set age=35,sex='m' where id=11;
	==>where id=1 or id=2 是代表1,2 变
	==>where id in(2,3,4)
	==>一个列 中的值进行更新 set-- where-and-
	==>where id>3  全改变..
	==>12 or 14 ==(12,14)
Query OK, 1 row affected (0.16 sec)
Rows matched: 1  Changed: 1  Warnings: 0

-- 将id值为12和14的数据值sex改为m，classid改为lamp92
mysql> update stu set sex='m',classid='lamp92' where id=12 or id=14 --等价于下面
mysql> update stu set sex='m',classid='lamp92' where id in(12,14);
Query OK, 2 rows affected (0.09 sec)
Rows matched: 2  Changed: 2  Warnings: 0
```

## 删除数据

> 格式：delete from 表名 [where 条件]

```
-- 删除stu表中id值为100的数据
mysql> delete from stu where id=100;
Query OK, 0 rows affected (0.00 sec)

-- 删除stu表中id值为20到30的数据
mysql> delete from stu where id>=20 and id<=30;
Query OK, 0 rows affected (0.00 sec)

-- 删除stu表中id值为20到30的数据（等级于上面写法）
mysql> delete from stu where id between 20 and 30;
		==>[20,30]包含
Query OK, 0 rows affected (0.00 sec)

-- 删除stu表中id值大于200的数据
mysql> delete from stu where id>200;
Query OK, 0 rows affected (0.00 sec)
```





# 1.6MySQL 数据操作 DQL

> 数据的DQL操作：数据查询
>
> 格式：
>
> ```
>     select [字段列表]  |  *  from 表名
> 
>     [where 搜索条件]
> 
>     [group by 分组字段 [having 子条件]]
> 
>     [order by 排序 asc|desc]
> 
>     [limit 分页参数]
> ```

## 数据的查询(基础查询)

```
mysql> select * from stu;
+----+----------+-----+-----+---------+
| id | name     | age | sex | classid |
+----+----------+-----+-----+---------+
|  1 | zhangsan |  20 | m   | lamp138 |
|  2 | lisi     |  20 | m   | lamp138 |
|  3 | wangwu   |  21 | w   | lamp138 |
|  4 | zhaoliu  |  25 | w   | lamp94  |
|  5 | uu01     |  26 | m   | lamp94  |
|  6 | uu02     |  28 | w   | lamp92  |
|  7 | qq02     |  24 | m   | lamp92  |
|  8 | uu03     |  32 | m   | lamp138 |
|  9 | qq03     |  23 | w   | lamp94  |
| 10 | aa       |  19 | m   | lamp138 |
| 11 | sad      |  35 | m   | lamp94  |
| 12 | tt       |  25 | m   | lamp92  |
| 13 | wer      |  25 | w   | lamp94  |
| 14 | xx       |  25 | m   | lamp92  |
| 15 | kk       |   0 | w   | lamp94  |
+----+----------+-----+-----+---------+
15 rows in set (0.00 sec)
```

## where条件查询

==>就是判断,and or(可以用逻辑运算符)

> - 你可以在 WHERE 子句中指定任何条件。
> - 你可以使用 AND 或者 OR 指定一个或多个条件。
> - WHERE 子句也可以运用于 SQL 的 DELETE 或者 UPDATE 命令。
> - WHERE 子句**类似于程序语言中的 if 条件**，根据 MySQL 表中的字段值来读取指定的数据。

```
1. 查询班级为lamp138期的学生信息
mysql> select * from stu where classid='lamp138';

2. 查询lamp138期的男生信息（sex为m）
mysql> select * from stu where classid='lamp138' and sex='m';

3. 查询id号值在10以上的学生信息
mysql> select * from  stu where id>10;

4. 查询年龄在20至25岁的学生信息
mysql> select * from stu where age>=20 and age<=25;
mysql> select * from stu where age between 20 and 25;

5. 查询年龄不在20至25岁的学生信息
mysql> select * from stu where age not between 20 and 25;
mysql> select * from stu where age<20 or age>25;

6. 查询id值为1,8,4,10,14的学生信息
select * from stu where id in(1,8,4,10,14);
mysql> select * from stu where id=1 or id=8 or id=4 or id=10 or id=14;

7. 查询lamp138和lamp94期的女生信息
mysql> select * from stu where classid in('lamp138','lamp94') and sex='w';
mysql> select * from stu where (classid='lamp138' or classid='lamp94') and sex='w

==> where age between 18 and 25 and class='py2'
    顺序执行.
    where id in(18,22,28)
    -and-  or  -and-
```

## LIKE 子句查询 (模糊查询)

> ==>%:代表任意位的任意字符
>
> ​	_:一位任意字符.
>
> ​	where  name like  '%龙%';
>
> ​	在实际开发中不建议将% 和_写在第一位,
>
> ​	写到第一位会造成索引使用不上.
>
> ​	是=换成like.
>
> ​	select * from stu where name  like'__';两个字

转义字符:

\d:单个数字

\D:单个的非数字

^:代表以指定字符开头

$:以指定字符结尾.(到了付dollar)

.:代表一位任意字符

*:匹配次数  匹配0次或者多次



regexp'.*\d';---不对

4$是以4结尾的..

> WHERE 子句中可以使用等号=来设定获取数据的条件，如 "runoob_author = 'RUNOOB.COM'"。
>
> 但是有时候我们需要获取 runoob_author 字段含有 "COM" 字符的所有记录，
>
> 这时我们就需要在 WHERE 子句中使用 SQL LIKE 子句。
>
> LIKE 子句中使用百分号%字符来表示任意字符，类似于UNIX或正则表达式中的星号*。
>
> 如果没有使用百分号%, LIKE 子句与等号=的效果是一样的。
>
> LIKE 通常与 % 一同使用，类似于一个元字符的搜索。
> 你可以使用 AND 或者 OR 指定一个或多个条件。
> 你可以在 DELETE 或 UPDATE 命令中使用 WHERE...LIKE 子句来指定条件。
> 可以使用regexp正则来代替 like

```
--9. 查询name字段值是以zh开头的所有信息(带zh)
mysql> select * from stu where name like "zh%";
mysql> select * from stu where name regexp  "^zh"; --正则写法
+----+----------+------+-----+---------+
| id | name     | age  | sex | classid |
+----+----------+------+-----+---------+
| 14 | zhangle  |   29 | m   |       5 |
|  1 | zhangsan |   20 | w   |       1 |
|  4 | zhaoliu  |   21 | m   |       4 |
+----+----------+------+-----+---------+
3 rows in set (0.00 sec)

--10.查询姓名name中含有ang子串的所有信息
mysql> select * from stu where name like "%ang%";
mysql> select * from stu where name regexp  "ang";
+----+-----------+------+-----+---------+
| id | name      | age  | sex | classid |
+----+-----------+------+-----+---------+
|  1 | zhangsan  |   20 | w   |       1 |
|  3 | wangwu    |   22 | w   |       5 |
| 10 | xiaozhang |   19 | w   |       1 |
| 13 | wangwen   |   27 | w   |       2 |
| 14 | zhangle   |   29 | m   |       5 |
+----+-----------+------+-----+---------+
5 rows in set (0.01 sec)


--11. 查询姓名是任意四位字符构成的信息。
mysql> select * from stu where name like "____";
mysql> select * from stu where name regexp "^[a-z0-9]{4}$";
+----+------+------+-----+---------+
| id | name | age  | sex | classid |
+----+------+------+-----+---------+
|  2 | lisi |   25 | m   |       2 |
|  5 | uu01 |   27 | w   |       1 |
|  6 | uu02 |   25 | m   |       2 |
|  7 | uu03 |   28 | w   |       2 |
|  8 | uu05 |   22 | m   |       4 |
+----+------+------+-----+---------+
5 rows in set (0.00 sec)
```

## MySQL的统计函数（聚合函数）：max() min() count() sum() avg()

avg()平均值;  count()统计;在数据分析中用到的多..

```
-- 获取学生表中最大、最小以及平均年龄是多少？
mysql> select max(age),min(age),avg(age) from stu;
+----------+----------+----------+
| max(age) | min(age) | avg(age) |
+----------+----------+----------+
|       29 |       19 |  24.5714 |
+----------+----------+----------+
1 row in set (0.00 sec)

-- 获取学生表中男生m的数量
mysql> select count(*) from stu where sex='m';
```

## GROUP BY 语句 分组

> GROUP BY 语句根据一个或多个列对结果集进行分组。
>
> 在分组的列上我们可以使用 COUNT, SUM, AVG,等函数。

```
-- 统计班级信息，按性别分组，并统计每组人数；
MySQL> select sex,count(*) from stu  group by sex;

-- 统计每个班级的人数
MySQL> select classid,count(*) from stu  group by classid;

-- 统计每个班级的，男生和女生各多少人数。
MySQL> select classid,sex,count(*) from stu  group by classid,sex;
```

## ORDER BY 排序 -- asc 默认升序 desc 降序

> 我们知道从 MySQL 表中使用 SQL SELECT 语句来读取数据。
>
> 如果我们需要对读取的数据进行排序，我们就可以使用 MySQL 的**ORDER BY**子句来设定你想按哪个字段哪种方式来进行排序，再返回搜索结果。
>
> - 你可以使用任何字段来作为排序的条件，从而返回排序后的查询结果。
> - 你可以设定多个字段来排序。
> - 你可以使用 ASC 或 DESC 关键字来设置查询结果是按升序或降序排列。 默认情况下，它是按升序排列。
> - 你可以添加 WHERE...LIKE 子句来设置条件。
>
> ```
> SELECT field1, field2,...fieldN table_name1, table_name2...
> ORDER BY field1, [field2...] [ASC [DESC]]
> ```

```
-- 按年龄升序排序查询学生信息
mysql> select * from stu order by age;
mysql> select * from stu order by age asc;  --默认asc升序 可省略
+----+-----------+------+-----+---------+
| id | name      | age  | sex | classid |
+----+-----------+------+-----+---------+
| 10 | xiaozhang |   19 | w   |       1 |
|  1 | zhangsan  |   20 | w   |       1 |
|  4 | zhaoliu   |   21 | m   |       4 |
| 11 | xiaoyan   |   22 | m   |       2 |
|  8 | uu05      |   22 | m   |       4 |
|  3 | wangwu    |   22 | w   |       5 |
|  6 | uu02      |   25 | m   |       2 |
|  2 | lisi      |   25 | m   |       2 |
|  5 | uu01      |   27 | w   |       1 |
| 13 | wangwen   |   27 | w   |       2 |
|  7 | uu03      |   28 | w   |       2 |
| 12 | xiaoxin   |   28 | w   |       4 |
|  9 | xiaoli    |   29 | w   |       2 |
| 14 | zhangle   |   29 | m   |       5 |
+----+-----------+------+-----+---------+
14 rows in set (0.01 sec)

-- 年龄降序排序
mysql> select * from stu order by age desc;
+----+-----------+------+-----+---------+
| id | name      | age  | sex | classid |
+----+-----------+------+-----+---------+
| 14 | zhangle   |   29 | m   |       5 |
|  9 | xiaoli    |   29 | w   |       2 |
| 12 | xiaoxin   |   28 | w   |       4 |
|  7 | uu03      |   28 | w   |       2 |
| 13 | wangwen   |   27 | w   |       2 |
|  5 | uu01      |   27 | w   |       1 |
|  2 | lisi      |   25 | m   |       2 |
|  6 | uu02      |   25 | m   |       2 |
| 11 | xiaoyan   |   22 | m   |       2 |
|  8 | uu05      |   22 | m   |       4 |
|  3 | wangwu    |   22 | w   |       5 |
|  4 | zhaoliu   |   21 | m   |       4 |
|  1 | zhangsan  |   20 | w   |       1 |
| 10 | xiaozhang |   19 | w   |       1 |
+----+-----------+------+-----+---------+
14 rows in set (0.00 sec)


-- 查询学生信息，按班级做升序排序，相同班级按年龄降序排序
mysql> select * from stu order by classid asc,age desc;
```

## limit 关键字 查询部分数据

> -- 例如： .... limit m; 查询数据只显示前m条
>
> -- 例如： .... limit m,n; 排除前m条，然后再查询出前n条

```
-- 查询前5条信息
mysql> select * from stu limit 5;
+----+----------+------+-----+---------+
| id | name     | age  | sex | classid |
+----+----------+------+-----+---------+
|  1 | zhangsan |   20 | w   |       1 |
|  2 | lisi     |   25 | m   |       2 |
|  3 | wangwu   |   22 | w   |       5 |
|  4 | zhaoliu  |   21 | m   |       4 |
|  5 | uu01     |   27 | w   |       1 |
+----+----------+------+-----+---------+
5 rows in set (0.00 sec)

-- 排除前2条后再获取4条信息
mysql> select * from stu limit 2,4;
+----+---------+------+-----+---------+
| id | name    | age  | sex | classid |
+----+---------+------+-----+---------+
|  3 | wangwu  |   22 | w   |       5 |
|  4 | zhaoliu |   21 | m   |       4 |
|  5 | uu01    |   27 | w   |       1 |
|  6 | uu02    |   25 | m   |       2 |
+----+---------+------+-----+---------+
4 rows in set (0.00 sec)

-- 以4条数据分一页，取第一页。
mysql> select * from stu limit 0,4;
+----+----------+------+-----+---------+
| id | name     | age  | sex | classid |
+----+----------+------+-----+---------+
|  1 | zhangsan |   20 | w   |       1 |
|  2 | lisi     |   25 | m   |       2 |
|  3 | wangwu   |   22 | w   |       5 |
|  4 | zhaoliu  |   21 | m   |       4 |
+----+----------+------+-----+---------+
4 rows in set (0.00 sec)

-- 以4条数据分一页，取第二页。
mysql> select * from stu limit 4,4;
+----+------+------+-----+---------+
| id | name | age  | sex | classid |
+----+------+------+-----+---------+
|  5 | uu01 |   27 | w   |       1 |
|  6 | uu02 |   25 | m   |       2 |
|  7 | uu03 |   28 | w   |       2 |
|  8 | uu05 |   22 | m   |       4 |
+----+------+------+-----+---------+
4 rows in set (0.00 sec)

-- 以4条数据分一页，取第三页。
mysql> select * from stu limit 8,4;
+----+-----------+------+-----+---------+
| id | name      | age  | sex | classid |
+----+-----------+------+-----+---------+
|  9 | xiaoli    |   29 | w   |       2 |
| 10 | xiaozhang |   19 | w   |       1 |
| 11 | xiaoyan   |   22 | m   |       2 |
| 12 | xiaoxin   |   28 | w   |       4 |
+----+-----------+------+-----+---------+
4 rows in set (0.00 sec)


-- 以4条数据分一页，取第四页。
mysql> select * from stu limit 12,4;
+----+---------+------+-----+---------+
| id | name    | age  | sex | classid |
+----+---------+------+-----+---------+
| 13 | wangwen |   27 | w   |       2 |
| 14 | zhangle |   29 | m   |       5 |
+----+---------+------+-----+---------+
2 rows in set (0.00 sec)

mysql> 
分页公式：.... (页号-1)*页大小, 页大小;

页号     limit语句                起始分页码数值是页大小的几倍。
---------------------------------------------------------------------
1       ... limit 0,4;                0
2       ... limit 4,4;                1
3       ... limit 8,4;                2
4       ... limit 12,4;            3
5       ... limit 16,4;            4
```

## 练习

```
-- 统计班级classid值为2的男女生各多少人？
mysql> select sex,count(*) from stu where classid=2 group by sex;

-- 获取年龄最大的5位学生信息？
mysql> select * from stu order by age desc limit 5;

-- 获取每个班级的平均年龄，并按平均年龄降序，
mysql> select classid,avg(age) from stu group by classid order by avg(age) desc;
mysql> select classid,avg(age) anum from stu group by classid order by anum desc;

-- 统计每个班级的人数，按人数从大到小排序，取前3条。
mysql> select classid,count(*) num from stu group by classid order by num desc limit 3;
```

查询去除重复的数据

```
select distinct 字段名 from tablename
```





# 1.7MySQL数据的导入和导出

## 数据导出

```
-- 将lamp138库导出
D:\>mysqldump -u root -p lamp138 >lamp138.sql
Enter password:
---- 将lamp138库中的stu表导出
D:\>mysqldump -u root -p lamp138 stu >lamp138_stu.sql
Enter password:
```

## 数据导入

```
-- 将lamp138库导入
D:\>mysql -u root -p lamp138<lamp138.sql
Enter password:
-- 将lamp138库中stu表导入
D:\>mysql -u root -p lamp138<lamp138_stu.sql
Enter password:
```

## 授权

> 格式：grant 允许操作 on 库名.表名 to 账号@来源 identified by '密码';

```
--实例：创建zhangsan账号，密码123，授权lamp61库下所有表的增/删/改/查数据,来源地不限
 mysql> grant select,insert,update,delete on lamp61.* to zhangsan@'%' identified by '123';
 mysql> grant all on *.* to zhangsan@'%' identified by '123';
 Query OK, 0 rows affected (0.00 sec)

 添加用户, 并授予在lamp189的数据库中可以对user表进行 查询和添加数据操作
 GRANT select,insert ON lamp189.user TO 'xxoo'@'%' IDENTIFIED BY 'abcd'

 删除用户
 drop user 'xxoo'@'%'
```

### MySQL忘记root密码

### windows

```
 1.结束正在运行的数据库服务器进程 mysqld.exe
 2.在DOS命令行执行 mysqld --skip-grant-tables
 3.再打开一个DOS窗口, 可直接输入 mysql 以管理员的身份强行进入.
 4. use mysql
 5. update user set authentication_string=password('新密码') where user='root';
 6. 刷新权限 flush privileges;
```

### Ubuntu 16.04 LTS

```
-- ubuntu 下, mysql忘记密码后重置mysql密码

-- 修改配置文件
 sudo vim /etc/mysql/mysql.conf.d/mysqld.cnf

 在[mysqld]的段中加上一句：skip-grant-tables 保存并且退出vim。


-- 重启mysqld
sudo /etc/init.d/mysqld restart


-- 登录并修改MySQL的root密码
mysql
mysql> USE mysql ; 
mysql> update mysql.user set authentication_string=password('abc123') where user='root' and Host = 'localhost';
mysql> flush privileges ; 
mysql> quit


-- 重新修改配置文件 把刚才添加的一句注释或者删除
 sudo vim /etc/mysql/mysql.conf.d/mysqld.cnf

-- 重新启动服务
 sudo /etc/init.d/mysqld restart

 -- 使用新密码重新登录mysql
 mysql -u root -pabc123
 mysql>
```







# 1.8python连接数据库

### 什么是 PyMySQL？

PyMySQL 是在 Python3.x 版本中用于连接 MySQL 服务器的一个库，Python2中则使用mysqldb。

PyMySQL 遵循 Python 数据库 API v2.0 规范，并包含了 pure-Python MySQL 客户端库。

------

## PyMySQL 安装

在使用 PyMySQL 之前，我们需要确保 PyMySQL 已安装。

PyMySQL 下载地址：<https://github.com/PyMySQL/PyMySQL。>

如果还未安装，我们可以使用以下命令安装最新版的 PyMySQL：

```
$ pip3 install PyMySQL
```

### 数据库连接

> 通过如下代码测试数据库连接

```
 #!/usr/bin/python3

 import pymysql

 # 打开数据库连接
 db = pymysql.connect("localhost","root","123456","mydb" )

 # 使用 cursor() 方法创建一个游标对象 cursor
 cursor = db.cursor()

 # 使用 execute()  方法执行 SQL 查询 
 cursor.execute("SELECT VERSION()")

 # 使用 fetchone() 方法获取单条数据.
 data = cursor.fetchone()

 print ("Database version : %s " % data)

 # 关闭数据库连接
 db.close()
```



# 1.9 python连接数据库 增删改查



## 执行数据添加

```
#!/usr/bin/python3

import pymysql

# 打开数据库连接
db = pymysql.connect("localhost","root","","mydemo" )

# 使用 cursor() 方法创建一个游标对象 cursor
cursor = db.cursor()

# SQL 插入语句
sql = "INSERT INTO stu(name,sex,age,classid) values('%s','%c','%d','%s')" % ('uu142','m',22,'lamp180') 

try:
   # 执行sql语句
   cursor.execute(sql)
   # 执行sql语句
   db.commit()
   print("ok: %d " % (cursor.rowcount))
except:
   # 发生错误时回滚
   db.rollback()

# 关闭数据库连接
db.close()
```

## 执行删除操作

```
 #!/usr/bin/python3

 import pymysql

 # 打开数据库连接
 db = pymysql.connect("localhost","root","","mydemo" )

 # 使用 cursor() 方法创建一个游标对象 cursor
 cursor = db.cursor()

 # SQL 删除语句
 sql = "delete from stu where id = '%d'" % (13)
 try:
    # 执行SQL语句
    cursor.execute(sql)
    # 提交修改
    db.commit()
 except:
    # 发生错误时回滚
    db.rollback()

 # 关闭数据库连接
 db.close()
```

## 执行数据修改|更新

```
#!/usr/bin/python3

import pymysql

# 打开数据库连接
db = pymysql.connect("localhost","testuser","test123","TESTDB" )

# 使用cursor()方法获取操作游标 
cursor = db.cursor()

# SQL 更新语句
sql = "UPDATE EMPLOYEE SET AGE = AGE + 1
                          WHERE SEX = '%c'" % ('M')
try:
   # 执行SQL语句
   cursor.execute(sql)
   # 提交到数据库执行
   db.commit()
except:
   # 发生错误时回滚
   db.rollback()

# 关闭数据库连接
db.close()
```

## 执行数据查询

> 数据库查询操作：
>
> ```
> Python查询Mysql使用 fetchone() 方法获取单条数据, 使用fetchall() 方法获取多条数据。
> 
>     fetchone(): 该方法获取下一个查询结果集。结果集是一个对象
> 
>     fetchall(): 接收全部的返回结果行.
> 
>     rowcount: 这是一个只读属性，并返回执行execute()方法后影响的行数。
> ```

```
 #!/usr/bin/python3

 import pymysql

 # 打开数据库连接
 db = pymysql.connect("localhost","root","","mydemo" )

 # 使用 cursor() 方法创建一个游标对象 cursor
 cursor = db.cursor()

 # SQL 查询语句
 sql = "select * from stu limit %d" % (3)
 #sql = "select * from stu"

 try:
    # 执行SQL语句
    cursor.execute(sql)
    # 获取所有记录列表
    results = cursor.fetchall()
    for row in results:
       id = row[0]
       name = row[1]
       sex = row[2]
       age = row[3]
       classid = row[4]
        # 打印结果
       print ("id=%d,name=%s,sex=%s,age=%d,classid=%s" % (id,name,sex,age,classid))
 except:
    print ("Error: unable to fetch data")

 # 关闭数据库连接
 db.close()
```







# 2.本小节内容简介

本章内容主要讲解 前端相关基础内容网页的结构，常见的标签和属性，css基本选择器，和基础的网络知识udp,tcp,http





# 2.1HTML概述和基本结构

# 网页的组成

网页由三部分组成

```
html: 结构层，主要负责页面的结构
css:  表现层，主要负责网页的样式
javascrapy: 行为层，主要负责用户的动态交互
```

## HTML是什么?

> <http://www.w3school.com.cn/index.html>
>
> HTML是 HyperText Mark-up Language 的首字母简写，意思是超文本标记语言，
>
> 超文本指的是超链接，标记指的是标签，是一种用来制作网页的语言，这种语言由一个个的标签组成，
>
> 用这种语言制作的文件保存的是一个文本文件，文件的扩展名为html或者htm，
>
> 一个html文件就是一个网页，html文件用编辑器打开显示的是文本，可以用文本的方式编辑它，
>
> 如果用浏览器打开，浏览器会按照标签描述内容将文件渲染成网页，显示的网页可以从一个网页链接跳转到另外一个网页。

## HTML是由：标签和内容构成

> <title>这是文档中的标题</title>

## HTML标签（标记）的语法：

> 标签是由"<"和">"括起来
>
> 双标签：<标签名>....</标签名>
>
> 单标签：<标签名/>

## HTML基本结构

```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>网页标题</title>
</head>
<body>
    网页显示内容
</body>
</html>
```

## html文档规范

> xhtml制定了文档的编写规范，html5可部分遵守，也可全部遵守，看开发要求。
>
> 1、所有的标签必须小写
>
> 2、所有的属性必须用双引号括起来
>
> 3、所有标签必须闭合
>
> 4、img必须要加alt属性(对图片的描述)

## html注释：

> html文档代码中可以插入注释，注释是对代码的说明和解释，注释的内容不会显示在页面上，html代码中插入注释的方法是：

```
<!-- 这是一段注释  -->
```



# 2.3HTML节点树



# 节点树及节点间的关系

在HTML中，所有标签定义的内容都是节点，它们构成了一个HTML DOM树。

根据W3C的HTML DOM标准，HTML文档中的所有内容都是节点。

- 整个文档是一个文档节点；
- 每个HTML元素是元素节点；
- HTML元素内的文本是文本节点；
- 每个HTML属性是属性节点；
- 注释是注释节点。

![img](./assets/2-12.jpg)

通过HTML DOM，树中的所有节点均可通过JavaScript访问

### 节点关系

节点树种的节点彼此用于层级关系，一般用parent child siblings来描述他们之间的关系

节点树中，顶端节点为根节点，除了根节点每个节点都有父节点，同时也拥有多个子节点和兄弟节点



# 2.4Css常用选择器

# Css基本语法及页面引用

### css基本语法

```
css的定义方法是：

选择器 { 属性:值; 属性:值; 属性:值;}

选择器是将样式和页面元素关联起来的名称，属性是希望设置的样式属性每个属性有一个或多个值。代码示例：

div{ width:100px; height:100px; color:red }
```

### css的页面引入方式

1.外联 通过link标签引入外部的css

```
<link rel="stylesheet" type="text/css" href="css/main.css">
```

2.嵌入式 通过style标签，在网页上创建嵌入的样式表。

```
<style type="text/css">

    div{ width:100px; height:100px; color:red }
    ......

</style>
```

3、内联式：通过标签的style属性，在标签上直接写样式。

```
<div style="width:100px; height:100px; color:red ">
......
</div>
```

# Css选择器

### 常用的选择器有如下几种：

1、标签选择器

标签选择器，此种选择器影响范围大，建议尽量应用在层级选择器中。

```
举例：
*{margin:0;padding:0}
div{color:red}   


<div>....</div>   <!-- 对应以上两条样式 -->
<div class="box">....</div>   <!-- 对应以上两条样式 -->
```

2、id选择器

通过id名来选择元素，元素的id名称不能重复，所以一个样式设置项只能对应于页面上一个元素，不能复用，id名一般给程序使用，所以不推荐使用id作为选择器。

```
举例：

#box{color:red} 

<div id="box">....</div>   <!-- 对应以上一条样式，其它元素不允许应用此样式 -->
```

3、类选择器

通过类名来选择元素，一个类可应用于多个元素，一个元素上也可以使用多个类，应用灵活，可复用，是css中应用最多的一种选择器。

```
举例：
.red{color:red}
.big{font-size:20px}
.mt10{margin-top:10px} 

<div class="red">....</div>
<h1 class="red big mt10">....</h1>
<p class="red mt10">....</p>
```

4、层级选择器

主要应用在选择父元素下的子元素，或者子元素下面的子元素，可与标签元素结合使用，减少命名，同时也可以通过层级，防止命名冲突。

```
举例：

.box span{color:red}
.box .red{color:pink}
.red{color:red}

<div class="box">
    <span>....</span>
    <a href="#" class="red">....</a>
</div>

<h3 class="red">....</h3>
```

5、组选择器

多个选择器，如果有同样的样式设置，可以使用组选择器。也成为 并列选择

```
举例：

.box1,.box2,.box3{width:100px;height:100px}
.box1{background:red}
.box2{background:pink}
.box2{background:gold}

<div class="box1">....</div>
<div class="box2">....</div>
<div class="box3">....</div>
```

6、伪类及伪元素选择器

常用的伪类选择器有hover，表示鼠标悬浮在元素上时的状态，伪元素选择器有before和after,它们可以通过样式在元素中插入内容。

```
.box1:hover{color:red}

<div class="box1">....</div>

a:hover {color: #FF00FF; text-decoration: underline} /* 鼠标在该元素上时 */


a:before{content:"Hello";}         /*在每个<a>元素之前插入内容*/
a:after{content:"world";}        /*在每个<a>元素之后插入内容*/
```

7.其他选择器(了解)

```
 .item>p{}                         子元素选择器:与后代选择器相比，子元素选择器只能选择某元素的子元素。 
 input[name=username]{}         属性选择器  :通过特定的属性来查找元素

 li:list-child{}                 选择最后一个li元素
 li:first-child{}                选择第一个li元素
 li:nth-child(2){}               选择指定的第几li元素
```





# 2.5网络简介

### 1.什么是网络

网络是辅助双方能够连接在一起的工具

#### 使用网络的目的

为了联通多方然后进行通讯，能够让软件在不同的电脑上运行，相互传输数据

### 网络协议

#### 什么是协议

> 约定俗成的，没有理由

### TCP/IP协议（族）

早期的计算机网络，都是由厂商自己规定的一套协议，IBM、Apple和Microsoft都有各自的网络协议，互不兼容 为了把全世界的所有不同类型的计算机连接起来，就必须规定一套全球通用的协议，为了实现互联网这个目标，互联网协议簇就是通用的协议标准。 因为互联网协议包含了上百种协议标准，但是最重要的两个协议是TCP和IP协议，所以，大家把互联网的协议简称TCP/IP协议

#### 常用的网络协议如图：

![img](assets/Snipaste_2017-11-21_09-30-23.png)

```
网络模型:
实际应用四层模型
链路层/网络接口层
网络层
传输层
应用层

理论七层网络模型:
物理层
数据链路层
网络层
传输层
会话层
表示层
应用层
```

### IP地址

#### 什么是地址

地址是用来标记地点的

#### IP地址的分类

每一个IP地址都包括两部分：网络地址和主机地址

![img](assets/Snipaste_2017-11-21_09-50-36.png)

A类IP地址

```
一个A类地址由1字节的网络地址和3字节主机地址组成，网络地址最高位必须是0
地址范围1.0.0.1-126.255.255.254
可用的A类网络有126个，每个网络能容纳1677214个主机
```

B类IP地址

```
一个B类地址由2个字节的网络地址和2个字节的主机地址组成，网络地址最高位必须是01
地址范围128.1.0.1-191.255.255.254
可用的B类网络有16384个，每个网络能容纳65534个主机
```

C类IP地址

```
一个C类地址由3个字节的网络地址和1个字节的主机地址组成，网络地址最高位必须是110
地址范围192.0.0.1-223.255.255.254
可用网络有2097152个，每个网络能容纳254个主机
```

D类IP地址多用于多点广播

```
D类IP地址第一个字节由1110开始，他是专门保留的地址。
他并不指向特定的网络，目前这一类地址备用在多点广播中
多点广播地址用来一次寻址一组计算机
地址范围224.0.0.1-239.255.255.254
```

E类IP地址

```
以1111开始，为将来使用保留
E类地址保留，仅实验和开发用
```

私有IP地址

```
在这么多网络IP中，中国规定有一部分IP地址是用于我们的局域王世勇，也就是属于私网IP，不在公网中使用的，他们的范围是：
10.0.0.0-1-255.255.255.255
172.16.0.0-172.31.255.255
192.168.0.0-192.168.255.255
```

注意

```
IP地址127.0.0.1-127.255.255.255用于回路测试，如：127.0.0.1可以代表本机IP，用http://127.0.0.1就可以测试本机配置的WEB服务
```

### 端口

#### 1.端口号

端口号是通过端口来标记的，范围是从0-65535

#### 2.端口号分类

端口号不是随意使用的，而是按照一定的规定进行分配的

端口号的分类有好几种，我们只介绍知名端口好和动态端口号

#### 知名端口

```
知名端口是众所周知的端口号，一般是从0-1023
80端口分配给HTTP服务
21端口分配给FTP服务
```

#### 动态端口

```
动态端口的范围一般是从1024到65535
之所以称之为动态端口，是因为它一般不固定分配某种服务，而是动态分配。
动态分配是指当一个系统进程或者应用程序进程需要网络通讯时，它向主机申请一个端口，主机从可用的端口号中分配一个供它使用
当这个进程关闭时，同事也就释放了所占用的端口号
```



# 2.6UDP协议和tcp协议

### UDP协议

UDP：用户数据报协议，不可靠性，只是把应用程序传给IP层数据报送出去，但是不能保证他们是否能到达目的地，传输数据报前不用再客户端和服务器之间建立连接，并且没有超时重发机制，所以传输速度快。

特点：

> 安全性差，传输速度快，无序，大小有限制64kb

TCP协议

> 在通讯之前，一定要先建立相关链接，才能发送数据

![img](./assets/Snipaste_2017-11-27_21-54-50.png)

```
建立连接 三次握手

ACK：确认标志
SYN：同步标志
第一次握手：主机A发送位码为syn＝1,随机产生seq number=1234567的数据包到服务器，主机B由SYN=1知道，A要求建立联机；

第二次握手：主机B收到请求后要确认联机信息，向A发送ack number=(主机A的seq+1),syn=1,ack=1,随机产生seq=7654321的包

第三次握手：主机A收到后检查ack number是否正确，即第一次发送的seq number+1,以及位码ack是否为1，若正确，主机A会再发送ack number=(主机B的seq+1),ack=1，主机B收到后确认seq值与ack=1则连接建立成功。

完成三次握手，主机A与主机B开始传送数据。
```

### TCP特点

安全性高，稳定性好，有序 速度相对较慢

### 使用python中的socked实现tcp和udp通讯

网络中进程之间如何通讯呢

首要解决的问题是如何确定你要和对方电脑上哪个进程进行通讯 利用协议，IP地址，端口标识网络的进程，然后通着这些标识进行通讯

### socket--UDP网络通讯

使用socket创建UDP

P通讯的过程很简单，如下图：

![img](../assets/Snipaste_2017-11-21_11-15-12.png)

使用代码实现：

```
服务端：
1.创建套接字对象
2.绑定ip地址和端口号
3.接受消息
4.返回消息
5.关闭套接字

import socket
# 创建套接字
udp_s = socket.socked(socket.AF_INET,socket.SOCK_DGRAM)
# 绑定ip地址
udp_s.bind(('',8080))
# 接受消息
data,addr = udp_s.recvfrom(1024)
print(data)

# 关闭套接字
udp_s.close()

客户端：
1.创建套接字对象
2.发送消息
3.关闭套接字对象

import socekd
# 创建套接字对象
udp_c = socket.socket(socket.AF_INET,socket.SOCK_DGRAM)
# 发送消息
udp_c.sendto('hello'.encode('utf-8'),('192.168.1.15',8080))
# 关闭套接字
udp_c.close()
```

### Socket--TCP网络通讯

TCP通讯过程

![img](./assets/Snipaste_2017-11-21_11-43-30.png)

```
服务端：
1.创建套接字对象
2.绑定ip地址和端口号
3.监听
4.接受消息
5.返回消息
6.关闭套接字

import socket
tcp_s = socket.socket(socket.AF_INET,socket.SOCK_STREAM)
tcp_s.bind(('',8080))
tcp_s.listen()
s,addr = tcp_s.accept()
data = s.recv(1024)
print(data.decode('utf-8'))
s.send('hello'.encode('utf-8))
s.close()
tcp_s.close()

客户端：
1.创建套接字对象
2.创建连接
3.发送消息
4.关闭套接字对象

import socket
tcp_c = socket.socket(socket.AF_INET,socket.SOCK_STRAM)
tcp_c.connect(('192.168.1.15',8080))
tcp_c.send('hello'.encode('utf-8'))
tcp_c.close()
```

 







# 2.7HTTP简介

HTTP协议主要工作在客户端-服务端的架构上，浏览器作为HTTP客户端通过URL向HTTP服务端即 WEB服务器发送请求，服务器根据接受到的请求，向客户端发送相应信息 超文本传输协议

### 超文本传输协议

是一种按照URL指示，将超文本文档从一台主机(Web服务器)传输到另一台主机(浏览器)的应用层协议，以实现超链接的功能。

### 超文本（Hyper Text）

包含有超链接(Link)和各种多媒体元素标记(Markup)的文本。这些超文本文件彼此链接，形成网状(Web)，因此又被称为网页(Web Page)。这些链接使用URL表示。最常见的超文本格式是超文本标记语言HTML。

### URL

URL即统一资源定位符(Uniform Resource Locator)，用来唯一地标识万维网中的某一个文档。URL由协议、主机和端口(默认为80)以及文件名几部分构成。

```
例：http://www.aspxfans.com:8080/news/index.asp?boardID=5ID=24618page=1#name
一个完整的URL包括以下几个部分
1.协议部分：该URL的协议部分为“http：”，这代表网页使用的是HTTP协议。在Internet中可以使用多种协议，如HTTP，FTP等等本例中使用的是HTTP协议。在"HTTP"后面的“//”为分隔符

2.域名部分：该URL的域名部分为“www.aspxfans.com”。一个URL中，也可以使用IP地址作为域名使用

3.端口部分：跟在域名后面的是端口，域名和端口之间使用“:”作为分隔符。端口不是一个URL必须的部分，如果省略端口部分，将采用默认端口

4.虚拟目录部分：从域名后的第一个“/”开始到最后一个“/”为止，是虚拟目录部分。虚拟目录也不是一个URL必须的部分。本例中的虚拟目录是“/news/”

5.文件名部分：从域名后的最后一个“/”开始到“？”为止，是文件名部分，如果没有“?”,则是从域名后的最后一个“/”开始到“#”为止，是文件部分，如果没有“？”和“#”，那么从域名后的最后一个“/”开始到结束，都是文件名部分。本例中的文件名是“index.asp”。文件名部分也不是一个URL必须的部分，如果省略该部分，则使用默认的文件名

6.锚部分：从“#”开始到最后，都是锚部分。本例中的锚部分是“name”。锚部分也不是一个URL必须的部分

7.参数部分：从“？”开始到“#”为止之间的部分为参数部分，又称搜索部分、查询部分。本例中的参数部分为“boardID=5ID=24618page=1”。参数可以允许有多个参数，参数与参数之间用“”作为分隔符。
```

# HTTP原理

### 请求响应模型

在用户点击URL,浏览器和服务器会执行哪些动作

- 1.浏览器分析超链接中的URL
- 2.浏览器向DNS请求解析www.sxtyu.com的IP地址
- 3.DNS将解析出的IP地址202.2.16.21返回浏览器
- 4.浏览器与服务器建立TCP连接(80端口)
- 5.浏览器请求文档：GET /index.html(发送HTTP请求)
- 6.服务器给出响应，将文档 index.html发送给浏览器
- 7.释放TCP连接
- 8.浏览器显示index.html中的内容

### 连接方式

- 1.非持久性连接
- 2.持久性连接

### 无状态性

是指同一个客户端(浏览器)第二次访问同一个Web服务器上的页面时，服务器无法知 道这个客户曾经访问过。HTTP的无状态性简化了服务器的设计，使其更容易支持大量并发的HTTP请求。

# HTTP报文结构

### 请求报文

即从客户端(浏览器)向Web服务器发送的请求报文。报文的所有字段都是ASCII码。

![img](./assets/Snipaste_2017-11-21_22-34-22.png)

### 返回报文

即从Web服务器到客户机(浏览器)的应答。报文的所有字段都是ASCII码。

![img](./assets/Snipaste_2017-11-21_22-36-02.png)

请求报头中的方法

方法(Method)是对所请求对象所进行的操作,也就是一些命令。请求报文中的操作有:

![img](./assets/Snipaste_2017-11-27_22-55-20.png)

- HEAD 类似GET请求，只不过返回的响应中没有具体内容，用于获取报头
- PUT 从客户端向服务器传送的数据取代指定文档中的内容
- DELETE 请求服务器删除指定的页面
- CONNECT 把服务器当作跳板，让服务器代替客户端访问其他网页
- OPTIONS 允许客户端查看服务器的性能
- TRACE 回显服务器收到的请求，主要用于测试或诊断

### 响应报文中的状态码

状态码(Status-Code)是响应报文状态行中包含的一个3位数字，指明特定的请求是否被满足，如果没有满足，原因是什么。状态码分为以下五类：

- 1xx：指示信息--表示请求已接收，继续处理。
- 2xx：成功--表示请求已被成功接收、理解、接受。
- 3xx：重定向--要完成请求必须进行更进一步的操作。
- 4xx：客户端错误--请求有语法错误或请求无法实现。
- 5xx：服务器端错误--服务器未能实现合法的请求。

常见状态代码、状态描述的说明如下

```
200 OK：客户端请求成功。
400 Bad Request：客户端请求有语法错误，不能被服务器所理解。
401 Unauthorized：请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用。
403 Forbidden：服务器收到请求，但是拒绝提供服务。
404 Not Found：请求资源不存在，举个例子：输入了错误的URL。
500 Internal Server Error：服务器发生不可预期的错误。
503 Server Unavailable：服务器当前不能处理客户端的请求，一段时间后可能恢复正常，举个例子：HTTP/1.1 200 OK（CRLF）。
```

### 请求头部

Accept：请求报头域，用于指定客户端可接受哪些类型的信息。

Accept-Language：指定客户端可接受的语言类型。

Accept-Encoding：指定客户端可接受的内容编码。

Host：用于指定请求资源的主机IP和端口号，其内容为请求URL的原始服务器或网关的位置。 从HTTP 1.1版本开始，请求必须包含此内容。

Cookie：也常用复数形式 Cookies， 这是网站为了辨别用户进行会话跟踪而存储在用户本地的数据。 它的主要功能是维持当前访问会话。 例如，我们输入用户名和密码成功登录某个网站后，服务器会用会话保存登录状态信息 ，后面我们每次刷新或请求该站点的其他页面时， 会发现都是登录状态，这就是Cookies的功劳。 Cookies里有信息标识了我们所对应的服务器的会话， 每次浏览器在请求该站点的页面时，都会在请求头中加上Cookies并将其发送给服务器， 服务器通过Cookies识别出是我们自己，并且查出当前状态是登录状态， 所以返回结果就是登录之后才能看到的网页内容。

Referer：此内容用来标识这个请求是从哪个页面发过来的， 服务器可以拿到这一信息并做相应的处理，如作来源统计、防盗链处理等。

User-Agent：简称UA，它是一个特殊的字符串头，可以使服务器识别客户使用的操作系统及版本、浏览器及版本等信息。 在做爬虫时加上此信息，可以伪装为浏览器；如果不加，很可能会被识别出为爬虫。

Content-Type：也叫互联网媒体类型（Internet Media Type）或者MIME类型， 在HTTP协议消息头中，它用来表示具体请求中的媒体类型信息。 例如，text/html代表HTML格式，image/gif代表GIF图片， application/json代表JSON类型，更多对应关系可以查看此对照表：<http://tool.oschina.net/commons。>

### 请求体

请求体一般承载的内容是POST请求中的表单数据，而对于GET请求，请求体则为空。 设置Content-Type为application/x-www-form-urlencoded，以表单数据的形式提交 Content-Type设置为application/json来提交JSON数据，或者设置为multipart/form-data来上传文件 在爬虫中，如果要构造POST请求，需要使用正确的Content-Type，并了解各种请求库的各个参数设置时使用的是哪种Content-Type，不然可能会导致POST提交后无法正常响应。

# 响应报文

### 响应头

Date：标识响应产生的时间。

Last-Modified：指定资源的最后修改时间。

Content-Encoding：指定响应内容的编码。

Server：包含服务器的信息，比如名称、版本号等。

Content-Type：文档类型，指定返回的数据类型是什么，如text/html代表返回HTML文档，application/x-javascript则代表返回JavaScript文件，image/jpeg则代表返回图片。

Set-Cookie：设置Cookies。响应头中的Set-Cookie告诉浏览器需要将此内容放在Cookies中，下次请求携带Cookies请求。

Expires：指定响应的过期时间，可以使代理服务器或浏览器将加载的内容更新到缓存中。如果再次访问时，就可以直接从缓存中加载，降低服务器负载，缩短加载时间。

### 响应体

响应的正文数据都在响应体中，比如请求网页时，它的响应体就是网页的HTML代码；请求一张图片时，它的响应体就是图片的二进制数据。我们做爬虫请求网页后，要解析的内容就是响应体

# HTTP代理

什么是HTTP代理

HTTP代理又称Web缓存或代理服务器(Proxy Server),是一种网络实体， 能代表浏览器发出HTTP请求，并将最近的一些请求和响应暂存在本地磁盘中， 当请求的Web页面先前暂存过，则直接将暂存的页面发给客户端(浏览器)，无须再次访问Internet。





# 3.爬虫

# python虚拟环境virtualenv

Virtualenv用于在一台机器上创建多个独立的python环境

可以让每一个python项目单独使用一个环境，而不会影响python系统环境，也不会影响其他环境

可以隔离项目之间三方包的依赖

# 安装

> pip install virtualenv

# 创建虚拟环境

> 在命令行里执行 virtualenv v1

# 激活虚拟环境

进入到v1中的Scripts目录下

> 执行 activate

命令行前面会多一个（v1）说明已经在虚拟环境中

# 退出虚拟环境

> deactivate

# pip的使用技巧 freeze

当我们在做项目迁移时肯定也要将依赖的三方模块在要被迁移的电脑上安装，一个一个安装很麻烦

> pip freeze > install.txt

安装时

> pip install -r install.txt







# 3.2urllib的使用





# 网络模块urllib

python内置了网络模块urllib，可以通过urllib模块发送网络请求

# urllib的使用

```
urllib 中有一个request方法

from urllib import request

# 定义请求地址
base_url = ''

# 发送get请求
response = request.urlopen(url=base_url)
```

### 构造请求头

有些网站会有些反爬手段 验证浏览器 所以我们要伪装我们的爬虫程序让他看起来更像是浏览器

```
from urllib import request

# 定义请求地址
base_url = ''
# 定义请求头
headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.84 Safari/537.36'

}
# 构造请求头
req = request.Request(url=base_url,headers=headers)

# 发送get请求
response = request.urlopen(req)

# 处理响应
html=response.read().decode('utf-8')

with open('./xici.html','w',encoding='utf-8') as f:
    f.write(html)
```

### url地址中文转码

urllib 中除了提供了request 还提供了parse用于处理url请求地址 中文要进行转码

```
from urllib import request,parse
# 定义请求地址
# http://www.baidu.com/s?wd=美女
# http://www.baidu.com/s?wd=%e7%be%8e%e5%a5%b3
base_url =  'http://www.baidu.com/s?'   

# 定义参数
data = {
    wd: '美女'
}

# 解析url
msg = parse.urlencode(data)
# 拼接url
url = base_url+msg

# 发送请求
response = request.urlopen(url=url)
```

# 解决ssl认证问题

https是基于ssl进行的加密认证，所以在发送https请求时需要认证证书，我们可以设置跳过认证

```
import ssl
ssl._create_default_https_context = ssl._create_unverified_context # 默认不需要校验网站证书
```

### 练习爬取百度翻译：当用户输入一个单词时通过脚本返回翻译的内容

提示发送post请求

> request.urlopen(url,data=data)

### 分析有道翻译 有反爬需要逆向解析

### 分析豆瓣的电影排行信息 抓取电影信息

### 分析百度贴吧 用户输入贴吧名 然后抓取每一页信息







# 3.3 urllib 解决登陆问题

# 模拟登陆问题

是否登录状态的验证使用了cookie he session所以我们要先了解他们

```
# cookie: 在浏览器中存储的信息 以 key=value
# session（会话）: 将数据存在服务无端  key=valye
#     当创建了一个session 会生成一个sessionid
#     将sessionid存入到本地浏览器当中的cookie
#     下次访问时就可以通过 提交的cookie 中的sessionid判断是否已经登录
```

有些网站需要登录认证以后才能看到一些页面

```
    1.直接获取 登陆以后的cookie，然后构造请求的时候带上cookie
        最暴力，最有效，也是最简单的，但是可能需要长期维护

    2.账号密码直接post到接口上
```

在模拟登录过程中，如果登录成功需要记录服务端返回的要设置的cookie信息

```
# 导包
from http import cookiejar

# 实例化cookie 管理器
cookie = cookiejar.CookieJar()
cookie_handler = request.HTTPCookieProcess(cookie)
# 实例化请求头 管理器
header = request.HTTPHandler()
headers = request.HTTPSHandler()
# 自定义请求方法
openter = request.build_openner(cookie_handler,header,headers)
# 构建请求头
req = request.Request(url,data=bytes(data,encoding="utf-8"))
# 发送请求时使用自定的openner
response = openner.open(req)

# 登陆成功后向首页发送请求
home_response = openner.open(url)
```





# 3.4urllib添加代理



# 代理的使用

代理的使用可以在一些方面提升数据采集的速度，和防止ip被封，也算是一种反反爬的手段

### 非认证代理的使用

```
# 定义代理 
proxy={
   'http': 'http://ip:prot',
   'https': 'https://ip:端口号'
}
# 创建代理对象
proxy_handler = request.ProxyHandler(proxy)
# 自定义请求方法
opener = requests.build_opener(proxy_handler)

# 发送请求
response = opener.open(url)
```

# 认证代理

```
# 定义代理
proxy = {
    'http':'http://user：password@ip:port',
    'https':'https://user：password@ip:port',
}
# 创建代理对象
proxy_handler = request.ProxyHandler(proxy)
# 自定义请求对象
opener = request.build_opener(proxy_handler)
# 发送请求
response = opener.open(url)
```

# 练习抓取66ip代理 将ip和端口号提取存到本地

# 抓取西祠代理ip 将ip和端口号提取存到本地









# 3.5正则re模块

# 正则表达式

又称规则表达式，通常被用来检索，替换符合某个规则的文本字符串

# re

主要功能

1.规则校验，邮箱，电话，账户，密码，ip (0-255.0-255.0-255.0-255)

2.在目标字符串中匹配定义规则的字符串 （爬虫）

# 常用方法：

```
compile: 将正则表达式模式编译成一个正则表达式对象
search：从字符串开始检索到结尾，返回第一次匹配到的内容
match : 默认在规则前边加上^
findall : 从头到尾检索，匹配所有符合规则的字符串，返回列表
finditera ：返回迭代器
```

# 普通字符

# 转义字符

```
\w  \W  \d  \D  \s  \S  
\w    #单个的字母数字下划线
\W    #单个的非字母数字下划线
\d    #单个数字字符
\D    #单个非数字字符
\s    #单个空白字符
\S    #单个的非空白字符
```

# 元字符

```
. * + ? {} [] () | ^ $
.                #除了换行外的其它任意字符
z*               #匹配0次或多次
z+               #匹配至少1次或多次
\w+?             #禁止贪婪 
\w{5}            #限制匹配的次数
\w{5,12}         #限制匹配5到12次
[a-z_A-Z0-9]+    #字符范围
\d+(\w+)\w+      #子组
abc|def|123      #或
^\$              #限制开始
a$               #限制结尾
```

# 练习

```
html = '''
<div>
    <ul>
        <li class="active" lsj id ="324234"
        >抽烟</li>
        <li>喝酒</li>
        <li>烫头</li>
        <li>洗脚</li>
    </ul>
</div>
'''
将li中的每一个文本内容匹配出来
```

# 爬取百度贴吧里的图片

urllib的request提供了 urlretrieve 可以下载图片和和视频

> request.urlretrieve(图片地址,存储路径)

# 抓取妹子图









# 3.7 requests的使用

requests 是一个第三方的网络模块，对urllib进行了封装，简化了urllib的操作，使用起来更方便

# 下载

> pip install requests

# get

```
   requests.get(url,headers=headers)
```

# post

requests 发送post请求数据不需要转码解析

```
   data={

   }
   requests.post(url,headers=headers,data=data)
```

# 添加代理

```
  proxy={
      'http': 'http://ip:port',
      'https': 'https://ip:port'
  }
  proxy={
      'http': 'http://user:password@ip:port',
      'https': 'https://user:password@ip:port'
  }
  requests.get(url,proxies=proxy)
```

# 构建会话信息

在urllib中想要存储cookie信息必须使用cookiejar 在requests中提供了一个方法

```
 # 实例化会话
 session = requests.session()

 # 发送请求
 session.get()
```

# 关于返回的数据

返回的数据requests使用response.text会自动帮我们转码,自动检测你使用的编码，但是有时候会出现乱码

我们可以全局的设置一下 response.encoding='' 在去用response.text 就是使用的设置的编码格式进行转码

如果我们想获取没有转码的字符 可以使用 response.content





# 4.解析模块

# 4.1 jsonpath的基本使用





# 数据处理json

JSON(JavaScript Object Notation) 是一种轻量级的数据交换格式，它使得人们很容易的进行阅读和编写。同时也方便了机器进行解析和生成。适用于进行数据交互的场景，比如网站前台与后台之间的数据交互。

json简单说就是javascript中的对象和数组，所以这两种结构就是对象和数组两种结构，通过这两种结构可以表示各种复杂的结构

### json模块

python中内置了json模块，提供了四个功能：dumps、dump、loads、load，用于字符串 和 python数据类型间进行转换。

### json.loads()

把Json格式字符串解码转换成Python对象 从json到python的类型转化对

### json.dumps()

返回一个str对象 把一个Python对象编码转换成Json字符串

json.dumps() 序列化时默认使用的ascii编码

添加参数 ensure_ascii=False 禁用ascii编码，按utf-8编码

### json.dump()

将Python内置类型序列化为json对象后写入文件

```
import json

listStr = [{"city": "北京"}, {"name": "zhansgan"}]
json.dump(listStr, open("listStr.json","w"), ensure_ascii=False)

dictStr = {"city": "北京", "name": "zhansgan"}
json.dump(dictStr, open("dictStr.json","w"), ensure_ascii=False)
```

### json.load()

读取文件中json形式的字符串元素 转化成python类型

```
import json

strList = json.load(open("listStr.json"))
print strList

# [{u'city': u'\u5317\u4eac'}, {u'name': u'\u5927\u5218'}]

strDict = json.load(open("dictStr.json"))
print strDict
# {u'city': u'\u5317\u4eac', u'name': u'\u5927\u5218'}
```

# jsonpath

JsonPath 是一种信息抽取类库，是从JSON文档中抽取指定信息的工具，提供多种语言实现版本，包括：Javascript, Python， PHP 和 Java。

官方文档：<http://goessner.net/articles/JsonPath>

```
JSONPath    描述

$            根节点
@             现行节点
.or[]        取子节点
..            就是不管位置，选择所有符合条件的条件
*            匹配所有元素节点
[]            迭代器标示（可以在里边做简单的迭代操作，如数组下标，根据内容选值等）
[,]            支持迭代器中做多选。
?()            支持过滤操作.
()            支持表达式计算
```

根据要求获取下面数据中的内容

```
{ "store": {
    "book": [ 
      { "category": "reference",
        "author": "Nigel Rees",
        "title": "Sayings of the Century",
        "price": 8.95
      },
      { "category": "fiction",
        "author": "Evelyn Waugh",
        "title": "Sword of Honour",
        "price": 12.99
      },
      { "category": "fiction",
        "author": "Herman Melville",
        "title": "Moby Dick",
        "isbn": "0-553-21311-3",
        "price": 8.99
      },
      { "category": "fiction",
        "author": "J. R. R. Tolkien",
        "title": "The Lord of the Rings",
        "isbn": "0-395-19395-8",
        "price": 22.99
      }
    ],
    "bicycle": {
      "color": "red",
      "price": 19.95
    }
  }
}
```

1.获取所有书籍的作者

2.获取所有的作者

3.获取所有的商品

4.获取所有的价格

5.获取第三本书的信息

6.获取字后一本书

7.获取前两本书

9.查找book中带有书号的书

10.价格少于10的书籍

# 练习

<http://www.lagou.com/lbs/getAllCitySearchLabels.json> 拉钩网城市数据

获取所有城市









# 4.2xpath的基本使用







# 什么是XPath

XPath (XML Path Language) 是一门在 XML 文档中查找信息的语言，可用来在 XML 文档中对元素和属性进行遍历。

W3School官方文档：<http://www.w3school.com.cn/xpath/index.asp>

# XML

• XML 指可扩展标记语言（EXtensible Markup Language）

• XML 是一种标记语言，很类似 HTML

• XML 的设计宗旨是传输数据，而非显示数据

• XML 的标签需要我们自行定义。

• XML 被设计为具有自我描述性。

• XML 是 W3C 的推荐标准

W3School官方文档：<http://www.w3school.com.cn/xml/index.asp>

# XML和HTML的区别

```
XML   可扩展标记语言      被设计为传输和存储数据，其焦点是数据的内容。
HTML  超文本标记语言      显示数据以及如何更好显示数据。
```

XML示例

```
<?xml version="1.0" encoding="utf-8"?>

<bookstore> 

  <book category="cooking"> 
    <title lang="en">Everyday Italian</title>  
    <author>Giada De Laurentiis</author>  
    <year>2005</year>  
    <price>30.00</price> 
  </book>  

  <book category="children"> 
    <title lang="en">Harry Potter</title>  
    <author>J K. Rowling</author>  
    <year>2005</year>  
    <price>29.99</price> 
  </book>  

  <book category="web"> 
    <title lang="en">XQuery Kick Start</title>  
    <author>James McGovern</author>  
    <author>Per Bothner</author>  
    <author>Kurt Cagle</author>  
    <author>James Linn</author>  
    <author>Vaidyanathan Nagarajan</author>  
    <year>2003</year>  
    <price>49.99</price> 
  </book> 

<bookstore>
```

# XPath选取节点

XPath使用路径表达式来选取XML文档中的节点或者节点集合。

| 表达式   | 描述                                                     |      |
| -------- | -------------------------------------------------------- | ---- |
| Nodename | 选取节点的所有子节点                                     |      |
| /        | 从根节点选取                                             |      |
| //       | 从匹配选择的当前节点选择文档中的节点，而不考虑他们的位置 |      |
| .        | 选取当前节点。                                           |      |
| ..       | 选取当前节点的父节点。                                   |      |
| @        | 选取属性。                                               |      |

# 谓语（Predicates）

谓语用来查找某个特定的节点或者包含某个指定的值的节点，被嵌在方括号中。

| 路径表达式                         | 结果                                                         |      |
| ---------------------------------- | ------------------------------------------------------------ | ---- |
| /bookstore/book[1]                 | 选取属于 bookstore 子元素的第一个 book 元素。                |      |
| /bookstore/book[last()]            | 选取属于 bookstore 子元素的最后一个 book 元素。              |      |
| /bookstore/book[last()-1]          | 选取属于 bookstore 子元素的倒数第二个 book 元素。            |      |
| /bookstore/book[position()<3]      | 选取最前面的两个属于 bookstore 元素的子元素的 book 元素。    |      |
| //title[@lang]                     | 选取所有拥有名为 lang 的属性的 title 元素。                  |      |
| //title[@lang=’eng’]               | 选取所有 title 元素，且这些元素拥有值为 eng 的 lang 属性。   |      |
| /bookstore/book[price>35.00]       | 选取 bookstore 元素的所有 book 元素，且其中的 price 元素的值须大于 35.00。 |      |
| /bookstore/book[price>35.00]/title | 选取 bookstore 元素中的 book 元素的所有 title 元素，且其中的 price 元素的值须大于 35.00。 |      |

# 选取未知节点

XPath 通配符可用来选取未知的 XML 元素。

| 通配符 | 描述                 |      |
| ------ | -------------------- | ---- |
| *      | 匹配任何元素节点。   |      |
| @*     | 匹配任何属性节点。   |      |
| node() | 匹配任何类型的节点。 |      |

示例：

| 路径表达式   | 结果                              |      |
| ------------ | --------------------------------- | ---- |
| /bookstore/* | 选取 bookstore 元素的所有子元素。 |      |
| //*          | 选取文档中的所有元素。            |      |
| //title[@*]  | 选取所有带有属性的 title 元素。   |      |

# 选取若干路径

通过在路径表达式中使用“|”运算符，您可以选取若干个路径。

| 路径表达式              | 结果         |                                                              |      |
| ----------------------- | ------------ | ------------------------------------------------------------ | ---- |
| //book/title \          | //book/price | 选取 book 元素的所有 title 和 price 元素。                   |      |
| //title \               | //price      | 选取文档中的所有 title 和 price 元素。                       |      |
| /bookstore/book/title \ | //price      | 选取属于 bookstore 元素的 book 元素的所有 title 元素，以及文档中所有的 price 元素。 |      |

# python中xpath的使用

lxml库 是 一个HTML/XML的解析器，主要的功能是如何解析和提取 HTML/XML 数据。

lxml和正则一样，也是用 C 实现的，是一款高性能的 Python HTML/XML 解析器，我们可以利用之前学习的XPath语法，来快速的定位特定元素以及节点信息。

lxml python 官方文档：<http://lxml.de/index.html>

# 安装

> pip install lxml

```
from lxml import etree
# 将字符串解析为html文档
html = etree.HTML(text)

# 按字符串序列化HTML文档 会自动补全标签
result = etree.tostring(html) 

res = html.xpath('xpath规则')
```

### xpath常见用法大全

```
from lxml import etree

html = '''
<bookstore> 
  <book price="100" category="cooking"> 
    <title lang="en">Everyday Italian</title>  
    <author>Giada De Laurentiis</author>  
    <year>2005</year>  
    <price>30.00</price> 
  </book>  

  <book category="children"> 
    <title lang="en">Harry Potter</title>  
    <author>J K. Rowling</author>  
    <year>2005</year>  
    <price>29.99</price> 
  </book>  

  <book category="web"> 
    <title category="web">XQuery Kick Start</title>  
    <author>James McGovern</author>  
    <author>Per Bothner</author>  
    <author>Kurt Cagle</author>  
    <author>James Linn</author>  
    <author>Vaidyanathan Nagarajan</author>  
    <year>2003</year>  
    <price>49.99</price> 
  </book> 

  <book category="web" cover="paperback"> 
    <title>Learning XML</title>  
    <author>Erik T. Ray</author>  
    <year>2003</year>  
    <price>39.95</price> 
  </book> 

</bookstore>

'''
html = etree.HTML(html) # 加载字符串
# html = etree.parse('temp.html') # 加载文件

# 构建xpath规则提取数据
# 获取所有的title 
# 获取book的cover属性和category属性
# 获取第一本书的信息
# 获取title具有属性lang的元素
# 获取title具有属性lang的元素 的内容
# 获取价格小于35.00的书的标题
# 获取所有书的价格和标题
# res = html.xpath('//book/title | //book/price') #


print(res)
```

# 练习 使用xpath分页爬取百度贴吧列表页 获取列表页的连接地址 在分别爬取详情页中的图片 并下载

# 糗事百科



# 4.3beautifusoup 的基本使用





# CSS 选择器：BeautifulSoup4

Beautiful Soup 也是一个HTML/XML的解析器，主要的功能也是如何解析和提取 HTML/XML 数据。

| 抓取工具      | 速度 | 使用难度 | 安装难度   |      |
| ------------- | ---- | -------- | ---------- | ---- |
| 正则          | 最快 | 困难     | 无（内置） |      |
| BeautifulSoup | 慢   | 最简单   | 简单       |      |
| lxml          | 快   | 简单     | 一般       |      |

lxml 只会局部遍历，而Beautiful Soup 是基于HTML DOM的，会载入整个文档，解析整个DOM树，因此时间和内存开销都会大很多，所以性能要低于lxml。

官方文档：<http://beautifulsoup.readthedocs.io/zh_CN/v4.4.0>

# 使用

安装：

> pip install beautifulsoup4

使用：

```
from bs4 import BeautifulSoup

text = """
    <html><head><title>The Dormouse's story</title></head>
    <body>
    <p class="title" id="p1"><b>The Dormouse's story</b><b>----2b</b></p>

    <p class="story">Once upon a time there were three little sisters; and their names were
    <a href="http://example.com/elsie" class="sister" id="link1"><span><b>Elsie</b></span></span>--alice</span></a>,
    <a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> and
    <a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>;
    and they lived at the bottom of a well.</p>

    <p class="story">...</p>
    <div>我是div</div>
    """

# 创建beautifulsoup对象
soup = BeautifulSoup(text,'lxml')

# 格式化输出
soup.prettify()
```

# 获取标签和标签属性

```
 tag = soup.p    
 获取标签名
 tag.name
 获取标签属性
 tag = soup.p['class']  #返回指定属性的值
 tag = soup.p.attrs     # 返回当前标签的所有属性
```

# 获取所有的子节点

```
soup.body.contents   # 返回列表形式
soup.body.children   # 返回迭代器类型
soup.body.denscendants  #返回所有后代元素
```

# find_all()

```
soup.find_all('p')   # 获取所有的p元素
soup.find_all('p'，attrs = {'class':'title'})   # 获取所有class=title的p元素
```

# 选择器的用法 ***

```
soup.select('p.title') # 获取class=title的素有p标签
soup.select('p .title') # 获取p里面class=title的素有元素
soup.select('#p1')      # 获取id=p1的元素
soup.select('p > a') # 获取p的子元素a
soup.select('p','div')
soup.select('a[class="item1"]')
soup.select('a[class]')
soup.select('a[class*="o"]')  #模糊查询
soup.select('a[class^="o"]') # 限制开头
soup.select('a[class$="0"]') # 限制结尾
```

# 获取文本和属性的方法

```
.text()
.get(src)
```

### 练习 使用bs4获取腾讯招聘的信息.





# 5.线程进程协议

# 本小节简介

### 进程

python实现多进程的方法，进程之间的通讯问题，进程池

### 线程

python多线程的实现方式，线程通讯问题，线程锁

### 协程



# 5.进程

# 进程的概念

cpu进行资源分配的最小单位

# 多进程

同时执行多个任务，比如一边听音乐一边写文档

# 进程VS程序

编写完成的代码，在没有执行的情况下叫做程序

正在执行的代码 叫进程

进程除了代码外，还需要运行环境，

# python中多进程实现的方法

python中mutiprocessing模块下有一个Process类，来帮助我们实现多进程

```
from multiprocessing import Process

if __name__=="__main__":
    # 创建进程
    p = Process()
    # 启动进程
    p.start()

Process的参数
target: 进程实例调用的对象
args:   对象的位置参数 元祖
kwargs: 对象的关键字收集参数 字典
name:   进程的别名
```

# 自定义进程的方法

继承系统的Process类

# 进程和进程之间通讯的问题

进程和进程之间是相互独立的，所以不会共享全局变量，为了实现数据的共享就需要使用 Queue

# 进程池

当需要创建的进程不多时可以使用multiprocess 手动创建，当需要创建的进程数量较大时，在手动创建工作量巨大，此时就可以使用multiprocess中的Pool

```
from multiprocess import Pool

if __name__ == "__main__":
    # 实例化进程池
    p = Pool()
    for i in range(3):
        p.apply_async(func,args=())
    p.close()
    p.join()
```

### Queue的使用

```
from multiprocessing import Queue

# 初始化Queue
q = Queue(3)

# 存消息
q.put('消息3')    # 如果消息队列已经满了 会阻塞 
q.put('消息'，True,2) # 等待两秒 强制添加
# 读消息
q.get()   # 如果消息队列 为空 会阻塞
q.get(True,2) # 等待两秒 强制获取

# 强制添加消息  如果队列已满会抛出异常
q.put_nowait('消息n')

# 强制获取
q.get_nowait()   # 如果消息队列为空 则抛出异常

# 检测消息队列是否已经满了
q.full()   # 满了返回True 没满返回False

# 检测消息是否为空
q.empty()    # 如过为空 返回True  不为空返回False


# 检测消息队列目前有多少个值
q.qsize()
```

# 练习：利用多进程实现 一个任务向消息队列写消息 一个任务负责读消息

### 进程池中的Queue

如果需要使用Pool创建进程，就需要使用multiprocessing.Manager()中的Queue

# 将腾讯升级成多进程爬取











# 5.2线程

线程（英语：thread）是操作系统能够进行运算调度的最小单位，一个进程中最少有一个进程

同一进程中的多条线程将共享该进程中的全部系统资源

# python中的线程

使用python的threading 模块

```
#创建
t = threading.Thread(target=func,args=())
# 启动
t.stat()
```

# 线程锁

多个线程会共享进程的资源

当多个线程同时操作一个全局变量时 有可能会造成全局变量的数据混乱，因此线程是不安全的

解决办法：加锁 或者使用消息队列

实例化锁 mutex = threading.Lock() 加锁： mutex.acquire([blocking]) blocking 为true 阻塞 反之不阻塞 释放锁： mutex.release()

# 将腾讯，糗事百科改成多线程 并对比多进程和多线程

# 多线程爬虫方案

![img]('/assets/2017-03-23_22223866.png')

# 总结进程VS线程

定义：

优缺点：

使用场景：











# 5.3协程

称为轻量级线程，用户线程，由程序控制

优点：程序之间切换消耗资源更小，并发量可以设置很大

# 6.Selenium的使用

是一个自动化测试工具,通过selenium 可以实现浏览器的点击，还有下拉等一系列操作，类似与按键精灵.

Selenium 官方参考文档：<http://selenium-python.readthedocs.io/index.html>

安装： pip install selenium

在使用selenium 是需要浏览器的配合，所以我们还要安装浏览器的驱动，

chromeDriver 是谷歌浏览器的驱动 所以在使用此驱动时必须保证安装了谷歌浏览器

chromeDriver的安装：

下载地址：<https://chromedriver.storage.googleapis.com/index.html>

下载之前一定先确定当前你浏览器的版本，下载与之对应的驱动

下载完成后，将ChromeDriver的可执行文件配置到环境变量下。或者将chromedriver.exe文件拖到Python的Scripts目录下

### 测试安装是否成功：

```
from selenium import webDriver
browser = webDriver.Chrome()
# 退出浏览器
# browser.quit()
```

如果弹出后闪退，则可能是ChromeDriver版本和Chrome版本不兼容

```
除了谷歌 火狐浏览器也提供了驱动GeckoDriver

下载地址：https://github.com/mozilla/geckodriver/releases

配置方法和谷歌一样
```

### 问题

使用selenium 配合浏览器会消耗较大的资源，所以在使用chrome 时我们可以做一些配置

```
from selenium import webdriver
from selenium.webdriver.chrome.options import  Options
chrome_options = Options()
#解决DevToolsActivePort文件不存在的报错
# chrome_options.add_argument('--no-sandbox')
#指定浏览器分辨率
# chrome_options.add_argument('window-size=1920x1080')
#谷歌文档提到需要加上这个属性来规避bug
# chrome_options.add_argument('--disable-gpu')
#隐藏滚动条, 应对一些特殊页面
# chrome_options.add_argument('--hide-scrollbars')
#不加载图片, 提升速度
# chrome_options.add_argument('blink-settings=imagesEnabled=false')
#浏览器不提供可视化页面. linux下如果系统不支持可视化不加这条会启动失败
chrome_options.add_argument('--headless')
#手动指定使用的浏览器位置
#chrome_options.binary_location=r'C:\Users\Administrator\AppData\Local\Google\Chrome\Application\chrome.exe'

# 实例化浏览器
driver = webdriver.Chrome(chrome_options=chrome_options)
```

# 设置请求头信息

```
from selenium import webdriver
# 进入浏览器设置
options = webdriver.ChromeOptions()
# 设置中文
options.add_argument('lang=zh_CN.UTF-8')
# 更换头部
options.add_argument('user-agent="Mozilla/5.0 (iPod; U; CPU iPhone OS 2_1 like Mac OS X; ja-jp) AppleWebKit/525.18.1 (KHTML, like Gecko) Version/3.1.1 Mobile/5F137 Safari/525.20"')
browser = webdriver.Chrome(chrome_options=options)
url = "https://www.baidu.com"
browser.get(url)
browser.quit()
```









# 6.1.PhantomJS的使用

phantomjs 无界面浏览器

selenium最新版本已经不支持PhantomJS但是我们可以通过对selenium降级来去使用它， 将selenium写在安装3.8版本

PhantomJS安装地址： <http://phantomjs.org/download.html>

# selenium的使用：

```
from selenium import webdriver

# 实例化浏览器
browser = webdriver.PhantomJS()

# 访问网页
browser.get('http://www.baidu.com')

# 输入搜索内容
browser.find_element_by_id('kw').send_keys('meinv')
# 单机搜索
browser.find_element_by_id('su').click()

# 输出代码
print(browser.page_source)

# 截图
browser.save_screenshop('图片名字‘)

# 退出浏览器
browser.quit()
```

配置PhantomJS请求头

```
from selenium import webdriver
import time
from selenium.webdriver.common.desired_capabilities import DesiredCapabilities

# 设置user-agent
dcap = dict(DesiredCapabilities.PHANTOMJS)
dcap["phantomjs.page.settings.userAgent"] = (
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:25.0) Gecko/20100101 Firefox/25.0 "
)

browser = webdriver.PhantomJS(desired_capabilities=dcap)
```





# 7.Scrapy 框架简介

# Scrapy 框架

Scrapy是用纯Python实现一个为了爬取网站数据、提取结构性数据而编写的应用框架，用途非常广泛。

框架的力量，用户只需要定制开发几个模块就可以轻松的实现一个爬虫，用来抓取网页内容以及各种图片，非常之方便。

Scrapy 使用了 Twisted['twɪstɪd](其主要对手是Tornado)异步网络框架来处理网络通讯，可以加快我们的下载速度，不用自己去实现异步框架，并且包含了各种中间件接口，可以灵活的完成各种需求。

# Scrapy架构 图(绿线是数据流向)：

![img](assets/截图.png)

- Scheduler(调度器): 它负责接受引擎发送过来的Request请求，并按照一定的方式进行整理排列，入队（Queue），当引擎需要时，交还给引擎。
- Downloader（下载器）：负责下载Scrapy Engine(引擎)发送的所有Requests请求，并将其获取到的Responses交还给Scrapy Engine(引擎)，由引擎交给Spider来处理，
- Spider（爬虫）：它负责处理所有Responses,从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给引擎，再次进入Scheduler(调度器)，
- Item Pipeline(管道)：它负责处理Spider中获取到的Item，并进行进行后期处理（详细分析、过滤、存储等）的地方.
- Downloader Middlewares（下载中间件）：你可以当作是一个可以自定义扩展下载功能的组件。
- Spider Middlewares（Spider中间件）：你可以理解为是一个可以自定扩展和操作引擎和Spider中间通信的功能组件（比如进入Spider的Responses;和从Spider出去的Requests）

# Scrapy的运作流程

```
代码写好，程序开始运行...
引擎：Hi！Spider, 你要处理哪一个网站？
Spider：老大要我处理xxxx.com。
引擎：你把第一个需要处理的URL给我吧。
Spider：给你，第一个URL是xxxxxxx.com。
引擎：Hi！调度器，我这有request请求你帮我排序入队一下。
调度器：好的，正在处理你等一下。
引擎：Hi！调度器，把你处理好的request请求给我。
调度器：给你，这是我处理好的request
引擎：Hi！下载器，你按照老大的下载中间件的设置帮我下载一下这个request请求
下载器：好的！给你，这是下载好的东西。（如果失败：sorry，这个request下载失败了。然后引擎告诉调度器，这个request下载失败了，你记录一下，我们待会儿再下载）
引擎：Hi！Spider，这是下载好的东西，并且已经按照老大的下载中间件处理过了，你自己处理一下（注意！这儿responses默认是交给def parse()这个函数处理的）
Spider：（处理完毕数据之后对于需要跟进的URL），Hi！引擎，我这里有两个结果，这个是我需要跟进的URL，还有这个是我获取到的Item数据。
引擎：Hi ！管道 我这儿有个item你帮我处理一下！调度器！这是需要跟进URL你帮我处理下。然后从第四步开始循环，直到获取完老大需要全部信息。
管道``调度器：好的，现在就做！
```

注意！只有当调度器中不存在任何request了，整个程序才会停止，（也就是说，对于下载失败的URL，Scrapy也会重新下载。）









# 7.1.Scrapy的安装介绍

Scrapy框架官方网址：<http://doc.scrapy.org/en/latest>

# Windows 安装方式

scrapy的安装之前需要安装这个模块：wheel、lxml、Twisted、pywin32，最后在安装scrapy

- pip install wheel
- <http://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted下载wheel文件> Twisted
- pip install Twisted‑17.5.0‑cp36‑cp36m‑win_amd64.whl
- 安装 pip install PyWin32
- pip install Scrapy

# Linux安装

```
Python 2 / 3
安装非Python的依赖 sudo apt-get install python-dev python-pip libxml2-dev libxslt1-dev zlib1g-dev libffi-dev libssl-dev
通过pip 安装 Scrapy 框架 sudo pip install scrapy
```







# 7.2 scrapy 项目创建

# 制作 Scrapy 爬虫 一共需要4步：

新建项目 (scrapy startproject xxx)：新建一个新的爬虫项目

明确目标 （编写items.py）：明确你想要抓取的目标

制作爬虫 （spiders/xxspider.py）：制作爬虫开始爬取网页

存储内容 （pipelines.py）：设计管道存储爬取内容

# 创建项目

scrapy startproject demo

# 启动项目

scrapy crawl name

# 创建爬虫

scrapy genspider name 域名

# 为了方便调试 我们可以在项目目录下创建一个main.py

from scrapy import cmdline cmdline.execute('scrapy crawl name'.split())

# 爬虫shell工具 一般用于调试

scrapy shell <http://www.baidu.com>

scrapy 提供了xpath 和css

在命令行中执行 >>> response.xpath('//title/text()')

[]

获取内容：>>> response.xpath('//title/text()')[0].extract()

'百度一下，你就知道'











# 7.3 scrapy图片下载

scrapy 内置了一个图片下载的管道，我们只需要在配置文件中加入图片下载管道，并做一些简单的配置就可以下载图片了

# 1.在配置文件管道配置中添加

‘scrapy.pipelines.images.ImagesPipeline':1

# 2.然后配置图片的下载目录

```
在配置文件中导入os
imports os
获取当前项目的根目录
BASE_DIR = os.path.dirname(os.path.dirname(__file__))
```

# 指定下载的字段

IMAGES_URLS_FIELD = 'pic_url'

# 设置图片下载路径 注意要在项目目录下创建goods_pic目录

IMAGES_STORE=os.path.join(BASE_DIR,'goods_pic')

# 3.在item储存数据时要存储列表类型

item['pic_url']=[pic_url]











# 7.4  User-Agent的随机切换

1.将user-agent写入settings中,在spider文件中导入并发送请求时使用，弊端是第一次请求没办法设置

2.使用第三方模块fake_useragent 使用此模块必须要有网

```
pip install fake_useragent
from fake_userage import UserAgent
ua = UserAgent()
ua.ie  获取ie的内核
ua.chrome 获取谷歌内核
ua.random 随机获取内核
```

3.在中间键配置请求头

为了减少代码的重复可以将他写入到中间建

```
from fake_userage import UserAgent
class RandomUserAgent(object):
    def __init__(self):
        self.ua = UserAjgent()
    def process_request(self,request,spider):
        ua = self.ua.random
        request.headers.setdefault('User-Agent',ua)
```

4.如果要指定使用某一个浏览器的内核

在配置文件中添加 UA_TYPE = 'chrome'

在中间键中导入配置文件

```
from fake_userage import UserAgent
from scrapy.conf import settings   # 导入配置文件的另一种方式
class RandomUserAgent(object):
    def __init__(self):
        self.ua = UserAjgent()
    def process_request(self,request,spider):
        # 获取浏览器类型
        ua_type = settings['UA_TYPE']
        # getattr 获取ua对象下的某一个值
        ua = getattr(self.ua,ua_type)
        request.headers.setdefault('User-Agent',ua)
```

5.使用全局的爬虫对象crawlder

```
class RandomUserAgent(object):
    def __init__(self,crawler):  # 接受 from_crawler 传过来的cralwer对象
        self.ua = UserAjgent()
        self.cralwer = cralwer  
    @classmethod
    def from_crawler(cls,crawler): # 此方法会自动将crawler传递进来
        # scrapy 可以通过crawler访问 cralwer.settings
        return cls(crawler)
    def process_request(self,request,spider):
        print(dir(self.cralwer))
        # getattr 获取ua对象下的某一个值
        ua = getattr(self.ua,self.cralwer.settings['UA_TYPE'])
        request.headers.setdefault('User-Agent',ua)
```





# 7.5scarapy代理



# 代理的添加

### 1. 普通代理的使用

在settings 中头添加

PROXIEX = [ {‘host’:'<http://ip:port'}> ... ]

### 2.在中间件中创建随机代理的中间建

```
class RandomProxy(object):

    def __init__(self,cralwer):
        self.cralwer = cralwer

    @classmethod
    def from_cralwer(cls,cralwer):
        return cls(cralwer)

    def process_request(self,request,spider):
        # 获取代理
        proxies = self.cralwer.settings['PROXIES']
        proxy = random.chice(proxies)

        request.meta = proxy['host']
```

# 3.开启配置文件中的配置信息

### 认证代理的使用

### 1.配置文件中添加

AUTH_PROXIES = [ {‘host’:'<http://ip:port','auth':'用户名：密码'}> ]

### 2.添加中间建

```
import base64

class RandomProxy(object):
    def __init__(self,cralwer):
        self.cralwer = cralwer

    @classmethod
    def from_cralwer(cls,cralwer):
        return cls(cralwer)

    def process_request(self,request,spider):
        # 获取代理
        auth_proxies = self.cralwer.settings['AUTH_PROXIES']
        proxy = random.choice(proxies)

        # 设置用户名和密码（用户名密码）  这里需要用到base64下的b4encode(bytes())
        auth = proxy['auth']
        auth = base64.b64encode(bytes(auth,''utf-8)).
        request.headers['Proxy-Authorization'] = b'Basic ' + auth

        # 设置代理ip和端口号
        request.meta['proxy'] = proxy['host']
```

```
https://www.gitbook.com/
```

```你
https://www.gitbook.com/
```

网址===







exit

# bye