---
文章基本Markdown写的。
同时也支持自己写css文件来控制排版。
---

# mnist

手写数字识别



### 数据集：

```
链接:https://pan.baidu.com/s/1sRjHRj-C2KxiDwMZkGn_yQ  密码:777c
参考： https://www.cnblogs.com/endlesscoding/p/9901539.html

获取数据
# from sklearn.datasets import fetch_mldata
# from sklearn import datasets

# mnist = fetch_mldata('MNIST   original') 
# mnist
```



### 误差分析

```
最后一种分类任务，被叫做"多输出-多分类"（或者简称多输出分类）。在这里每一个标签可以是多类别的（比如我们前面所举的例子）

为了说明这点，我们建立一个系统，它可以去除图片当中的噪音。它将一张混有噪音的图片作为输入，期待它输出一张干净的数字图片，用一个像素强度的数组表示，就像 MNIST图片那样。注意到这个分类器的输出是多标签的（一个像素一个标签）和每个标签可以有多个值 （像素强度取值范围从0到255）。所以它是一个多输出分类系统的例子。

我们从MNIST的图版创建训练集和测试集开始，然后给图片的像素强度添加噪声，这里是用NumPy的randint()函数。目标图像是原始图像
```



![mnist](/images/手写识别.png)











```python
import numpy as np

def sigmoid(Z):
    return 1 / (1 + np.exp(-Z))

# sigmoid求导
def sigmoid_backward(dA, Z):
    s = 1 / (1 + np.exp(-Z))
    dZ = dA * s * (1 - s)
    return dZ

def relu(Z):
    return np.maximum(0, Z)

# relu求导
def relu_backward(dA, Z):
    dZ = np.array(dA, copy=True)
    dZ[Z <= 0] = 0
    return dZ

# 初始化
def init_parameters(layers_dim):

    m = len(layers_dim)
    parameters = {}
    for i in range(1, m):
        parameters['W' + str(i)] = np.random.randn(layers_dim[i], layers_dim[i-1]) / np.sqrt(layers_dim[i-1])
        parameters['b' + str(i)] = np.zeros((layers_dim[i], 1))

    return parameters


# 前向传播
def forward_propagation(x, parameters):

    W1 = parameters['W1']
    b1 = parameters['b1']
    W2 = parameters['W2']
    b2 = parameters['b2']

    Z1 = np.dot(W1, x) + b1
    A1 = relu(Z1)
    Z2 = np.dot(W2, A1) + b2
    A2 = sigmoid(Z2)

    return A2, (Z1, A1, Z2, A2)


# 反向传播
def backward_propagation(x, y, cache, parameters):

    m = x.shape[1]
    W2 = parameters['W2']

    (Z1, A1, Z2, A2) = cache

    da2 = - (np.divide(y, A2) - np.divide(1 - y, 1 - A2))
    dz2 = sigmoid_backward(da2, Z2)
    dW2 = np.dot(dz2, A1.T) / m
    db2 = np.sum(dz2, axis=1, keepdims=True) / m

    da1 = np.dot(W2.T, dz2)
    dz1 = relu_backward(da1, Z1)
    dW1 = np.dot(dz1, x.T) / m
    db1 = np.sum(dz1, axis=1, keepdims=True) / m

    gradients = {"da2": da2, "dz2": dz2, "dW2": dW2, "db2": db2,
                 "da1": da1, "dz1": dz1, "dW1": dW1, "db1": db1}

    return gradients


def compute_cost(a2, a):
    m = a2.shape[1]

    cost = -np.sum(np.multiply(np.log(a2), a) + np.multiply(np.log(1 - a2), 1 - a)) / m
    cost = float(np.squeeze(cost))

    return cost


def update_parameters_with_grad(parameters, grads, learning_rate=0.01):
    L = len(parameters) // 2
    for l in range(L):
        parameters["W" + str(l + 1)] = parameters["W" + str(l + 1)] - learning_rate * grads["dW" + str(l + 1)]
        parameters["b" + str(l + 1)] = parameters["b" + str(l + 1)] - learning_rate * grads["db" + str(l + 1)]
    # 返回更新后的参数
    return parameters

def model(train_x, train_y, layers_dims, learning_rate=0.0001, num_iterations=1000, print_cost=True):
    print("Training")
    parameters = init_parameters(layers_dims)

    for i in range(num_iterations):
        A2, cache = forward_propagation(train_x, parameters)
        cost = compute_cost(A2, train_y)
        gradients = backward_propagation(train_x, train_y, cache, parameters)
        parameters = update_parameters_with_grad(parameters, gradients, learning_rate)

        if print_cost and i % 50 == 0:
            print("Cost after %i : %i :%f" % (i, num_iterations, cost))

    return parameters

# 测试
def predict(x, y, parameters):
    print("Predicting")
    m = x.shape[1]
    a2, _ = forward_propagation(x, parameters)
    predict_result = np.where(a2 > 0.5, 1, 0)

    count = 0
    tmp = list(predict_result.T == a2.T)
    for i in tmp:
        if False in i:
            count += 1
    accuracy = 1-count/m
    print(predict_result.T)
    print(y.T)
    return accuracy

# 读入数据
# 格式为X(784,m) Y(10,m)
def load_dataset(url, m):
    print("Data loading")
    examples = []
    labels = []
    fr = open(url, 'r')
    lines = fr.readlines()
    lines = lines[:m]
    for line in lines:
        curLine = line.strip().split(',')
        tmp = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
        y = int(curLine[0])
        tmp[y] = 1
        labels.append(tmp)
        examples.append([int(num) / 255 for num in curLine[1:]])

    labels = np.array(labels).T
    examples = np.array(examples).T

    return examples, labels


if __name__ == '__main__':
    train_x, train_y = load_dataset('D:\Code\MLearing\MultiLayer\MNIST_Adam\mnist_train.csv', 300)
    test_x, test_y = load_dataset('D:\Code\MLearing\MultiLayer\MNIST_Adam\mnist_test.csv', 100)

    layers = [train_x.shape[0], 128, train_y.shape[0]]

    parameters_ = model(train_x, train_y, layers_dims=layers)

    accuracy_ = predict(test_x, test_y, parameters_)
    print("Accuracy %f" % accuracy_)
```

